{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto Grupo BT-G3\n"
      ],
      "metadata": {
        "id": "W6orTJnannWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Integrantes do grupo**\n",
        "- Daniel Barzilai\n",
        "- Larissa Carvalho\n",
        "- Maria Luisa Maia\n",
        "- Pedro Rezende\n",
        "- Rafael Moritz\n",
        "- Vitor Oliveira"
      ],
      "metadata": {
        "id": "wnoVqdIxSmPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://www.inteli.edu.br/wp-content/uploads/2021/08/20172028/marca_1-2.png\" width=\"50%\" height=\"50%\"/></center>"
      ],
      "metadata": {
        "id": "k0U6vMkgcCOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align='center'><b>IA para Marketing: Monitoramento de campanhas utilizando processamento de linguagem natural (PLN)<b></h1>"
      ],
      "metadata": {
        "id": "GntQpF9HcHF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c2/Btg-logo-blue.svg\" width=\"50%\" height=\"50%\"/></center>"
      ],
      "metadata": {
        "id": "geZEZyxccIwj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9VKvL0NZMFOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align='center'>O Banco BTG Pactual enfrenta um desafio na área de Marketing em entender as necessidades e demandas dos clientes de maneira fácil e rápida nas redes sociais. A solução proposta para esse problema foi o desenvolvimento de uma Inteligência Artificial utilizando processamento de linguagem natural (PLN), capaz de monitorar as campanhas de marketing, voltadas para o Instagram. O objetivo principal dessa solução é rastrear os dados em tempo real, analisar e interpretar as mensagens e comentários enviados pelos clientes na rede social, a fim de identificar as necessidades e demandas de forma precisa e eficiente.</h2>"
      ],
      "metadata": {
        "id": "GDi4jBLdcIoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "d9cjCQyEcPhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sobre os dados"
      ],
      "metadata": {
        "id": "YsbJTy0IcTIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse projeto está utilizando dados coletados e tratados pela equipe de Automation do BTG Pactual, o qual disponibilizou o dataset. Com base nas informações dispostas nesse dataset, realizaremos insights a cerca dos comentários feitos nos posts do Instagram do próprio banco. Vale lembrar que os dados estão anonimizados e resguardados para manter a privacidade e ética com os usuários e com o banco."
      ],
      "metadata": {
        "id": "3-s3rB_1cVPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Instalação / Setup"
      ],
      "metadata": {
        "id": "jCzVQHGx6tux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o início do projeto, fizemos o desenvolvimento no Google Colab, por isso temos uma célula de conexão com o Google Drive, para poder acessar os dados. Caso seja rodado no Jupyter Notebook, precisará do dataset baixado."
      ],
      "metadata": {
        "id": "-werU6i-qvLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conectar com o Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Conectando o ambiente ao Google Drive"
      ],
      "metadata": {
        "id": "ae8sAINTP6Lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847f6236-d8c5-47b3-9828-3f618892710d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui nós fazemos as importações para tratamento dos dados, pré-processamento dos dados e modelamento do Bag of Words. "
      ],
      "metadata": {
        "id": "nuIt1T3cwjSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pips"
      ],
      "metadata": {
        "id": "iNmxBn3LsHfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "id": "FNoqph3MTSbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc5a960-ff75-4622-e79e-83863819fe02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.2\n",
            "    Uninstalling spacy-3.5.2:\n",
            "      Successfully uninstalled spacy-3.5.2\n",
            "Successfully installed spacy-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "metadata": {
        "id": "teLWG2aVTlgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99768415-9522-4535-8a01-d381274f14f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from wordcloud) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "qH7Wx6XcGgWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4a1326-c42f-4311-ce17-ed426047a2da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "U-H1Fg8pHHaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9e8fd8-82e1-42f4-c1cf-aa09e76129f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "1JrWyVj-HOhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b27ed5-9c0e-43ab-bb9d-8e87f11fecaf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "iYpVFSrssMXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import ast\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential \n",
        "from keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "import gensim\n",
        "import pickle\n",
        "from scipy.spatial.distance import cosine\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "5INUqxN_NPZ9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O desenvolvimento da rede neural seguiu o tutorial abaixo:\n",
        "https://medium.com/@jvsavietto6/classificando-texto-com-redes-neurais-artificiais-150ef448b13d"
      ],
      "metadata": {
        "id": "v4c2e5c3LwxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Entendimento e Tratamento dos Dados"
      ],
      "metadata": {
        "id": "dDAJ_PlDObbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rodando o dataset, para analisar seu conteúdo:"
      ],
      "metadata": {
        "id": "MgoZgBnOxFul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Módulo 6/Sprint 3 - Projeto/nova_base_tratada (1)')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1xoda_aCFesh",
        "outputId": "fbd56ce8-6225-4101-a0b5-a2f80383c0c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                     autor  sentimento  \\\n",
              "0              0             winthegame_of           1   \n",
              "1              1                marta_bego           1   \n",
              "2              2                lmviapiana           2   \n",
              "3              3              vanilson_dos           1   \n",
              "4              4               ricktolledo           2   \n",
              "...          ...                       ...         ...   \n",
              "9202        9472  perspectiveinvestimentos           2   \n",
              "9203        9473            eduardocolares           2   \n",
              "9204        9474                 danielucm           2   \n",
              "9205        9475          amgcapitalinvest           1   \n",
              "9206        9476                 bfmarilia           0   \n",
              "\n",
              "                                          texto_tratado  \n",
              "0     ['alvarez', 'marsal', 'estar', 'conosco', 'spo...  \n",
              "1     ['btgpactual', 'with', 'makerepost', 'entender...  \n",
              "2                           ['minuto', 'touro', 'ouro']  \n",
              "3                                               ['sim']  \n",
              "4     ['querer', 'saber', 'banking', 'próprio', 'adm...  \n",
              "...                                                 ...  \n",
              "9202                        ['excelente', 'explicação']  \n",
              "9203            ['atendar', 'telefone', 'amor', 'deus']  \n",
              "9204  ['saber', 'qual', 'grande', 'fiis', 'mercado',...  \n",
              "9205  ['erro', 'financeiro', 'eliminar', 'antes', 'a...  \n",
              "9206  ['porque', 'morning', 'call', 'aparecer', 'spo...  \n",
              "\n",
              "[9207 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6f3095d-6add-4175-bc0b-07a07c08bbcc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>autor</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>texto_tratado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>winthegame_of</td>\n",
              "      <td>1</td>\n",
              "      <td>['alvarez', 'marsal', 'estar', 'conosco', 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>marta_bego</td>\n",
              "      <td>1</td>\n",
              "      <td>['btgpactual', 'with', 'makerepost', 'entender...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lmviapiana</td>\n",
              "      <td>2</td>\n",
              "      <td>['minuto', 'touro', 'ouro']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>vanilson_dos</td>\n",
              "      <td>1</td>\n",
              "      <td>['sim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ricktolledo</td>\n",
              "      <td>2</td>\n",
              "      <td>['querer', 'saber', 'banking', 'próprio', 'adm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>9472</td>\n",
              "      <td>perspectiveinvestimentos</td>\n",
              "      <td>2</td>\n",
              "      <td>['excelente', 'explicação']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>9473</td>\n",
              "      <td>eduardocolares</td>\n",
              "      <td>2</td>\n",
              "      <td>['atendar', 'telefone', 'amor', 'deus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>9474</td>\n",
              "      <td>danielucm</td>\n",
              "      <td>2</td>\n",
              "      <td>['saber', 'qual', 'grande', 'fiis', 'mercado',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>9475</td>\n",
              "      <td>amgcapitalinvest</td>\n",
              "      <td>1</td>\n",
              "      <td>['erro', 'financeiro', 'eliminar', 'antes', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>9476</td>\n",
              "      <td>bfmarilia</td>\n",
              "      <td>0</td>\n",
              "      <td>['porque', 'morning', 'call', 'aparecer', 'spo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6f3095d-6add-4175-bc0b-07a07c08bbcc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6f3095d-6add-4175-bc0b-07a07c08bbcc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6f3095d-6add-4175-bc0b-07a07c08bbcc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "J5GWQzKeRFGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7cbd31-5c6d-4eb5-d139-eab0d5b015b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'autor', 'sentimento', 'texto_tratado'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "SWFRdnQ2Vwob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f4fe759c-7898-41d1-ae04-d64fa12e141a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         autor  sentimento  \\\n",
              "0                winthegame_of           1   \n",
              "1                   marta_bego           1   \n",
              "2                   lmviapiana           2   \n",
              "3                 vanilson_dos           1   \n",
              "4                  ricktolledo           2   \n",
              "...                        ...         ...   \n",
              "9202  perspectiveinvestimentos           2   \n",
              "9203            eduardocolares           2   \n",
              "9204                 danielucm           2   \n",
              "9205          amgcapitalinvest           1   \n",
              "9206                 bfmarilia           0   \n",
              "\n",
              "                                          texto_tratado  \n",
              "0     ['alvarez', 'marsal', 'estar', 'conosco', 'spo...  \n",
              "1     ['btgpactual', 'with', 'makerepost', 'entender...  \n",
              "2                           ['minuto', 'touro', 'ouro']  \n",
              "3                                               ['sim']  \n",
              "4     ['querer', 'saber', 'banking', 'próprio', 'adm...  \n",
              "...                                                 ...  \n",
              "9202                        ['excelente', 'explicação']  \n",
              "9203            ['atendar', 'telefone', 'amor', 'deus']  \n",
              "9204  ['saber', 'qual', 'grande', 'fiis', 'mercado',...  \n",
              "9205  ['erro', 'financeiro', 'eliminar', 'antes', 'a...  \n",
              "9206  ['porque', 'morning', 'call', 'aparecer', 'spo...  \n",
              "\n",
              "[9207 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ae14567-ddd2-4588-a463-f601841a0848\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>autor</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>texto_tratado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>winthegame_of</td>\n",
              "      <td>1</td>\n",
              "      <td>['alvarez', 'marsal', 'estar', 'conosco', 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marta_bego</td>\n",
              "      <td>1</td>\n",
              "      <td>['btgpactual', 'with', 'makerepost', 'entender...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmviapiana</td>\n",
              "      <td>2</td>\n",
              "      <td>['minuto', 'touro', 'ouro']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vanilson_dos</td>\n",
              "      <td>1</td>\n",
              "      <td>['sim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ricktolledo</td>\n",
              "      <td>2</td>\n",
              "      <td>['querer', 'saber', 'banking', 'próprio', 'adm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>perspectiveinvestimentos</td>\n",
              "      <td>2</td>\n",
              "      <td>['excelente', 'explicação']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>eduardocolares</td>\n",
              "      <td>2</td>\n",
              "      <td>['atendar', 'telefone', 'amor', 'deus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>danielucm</td>\n",
              "      <td>2</td>\n",
              "      <td>['saber', 'qual', 'grande', 'fiis', 'mercado',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>amgcapitalinvest</td>\n",
              "      <td>1</td>\n",
              "      <td>['erro', 'financeiro', 'eliminar', 'antes', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>bfmarilia</td>\n",
              "      <td>0</td>\n",
              "      <td>['porque', 'morning', 'call', 'aparecer', 'spo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ae14567-ddd2-4588-a463-f601841a0848')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ae14567-ddd2-4588-a463-f601841a0848 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ae14567-ddd2-4588-a463-f601841a0848');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['texto_tratado']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LkWLbegZdYE",
        "outputId": "ec9486f1-8c9a-445c-f076-9c3a7f8e8e40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ['alvarez', 'marsal', 'estar', 'conosco', 'spo...\n",
              "1       ['btgpactual', 'with', 'makerepost', 'entender...\n",
              "2                             ['minuto', 'touro', 'ouro']\n",
              "3                                                 ['sim']\n",
              "4       ['querer', 'saber', 'banking', 'próprio', 'adm...\n",
              "                              ...                        \n",
              "9202                          ['excelente', 'explicação']\n",
              "9203              ['atendar', 'telefone', 'amor', 'deus']\n",
              "9204    ['saber', 'qual', 'grande', 'fiis', 'mercado',...\n",
              "9205    ['erro', 'financeiro', 'eliminar', 'antes', 'a...\n",
              "9206    ['porque', 'morning', 'call', 'aparecer', 'spo...\n",
              "Name: texto_tratado, Length: 9207, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que seu DataFrame seja chamado de df e a coluna seja 'texto_tratado'\n",
        "df['texto_tratado'] = df['texto_tratado'].str.replace(\"'\", \"\")\n",
        "df['texto_tratado']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BenRWfG2U8JM",
        "outputId": "97563137-a3df-463e-891c-27e9e3f95f54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [alvarez, marsal, estar, conosco, sportainmet,...\n",
              "1       [btgpactual, with, makerepost, entender, impac...\n",
              "2                                   [minuto, touro, ouro]\n",
              "3                                                   [sim]\n",
              "4           [querer, saber, banking, próprio, administro]\n",
              "                              ...                        \n",
              "9202                              [excelente, explicação]\n",
              "9203                      [atendar, telefone, amor, deus]\n",
              "9204    [saber, qual, grande, fiis, mercado, selecione...\n",
              "9205    [erro, financeiro, eliminar, antes, ano, _, pa...\n",
              "9206    [porque, morning, call, aparecer, spotify, atu...\n",
              "Name: texto_tratado, Length: 9207, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Word2Vec com CBOW"
      ],
      "metadata": {
        "id": "y4KhJVXLK7W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estruturação"
      ],
      "metadata": {
        "id": "1BXIKk0Ud470"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "dgxQlJajLDF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a3d22c7a-5ece-4058-bec3-a0359c19e846"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         autor  sentimento  \\\n",
              "0                winthegame_of           1   \n",
              "1                   marta_bego           1   \n",
              "2                   lmviapiana           2   \n",
              "3                 vanilson_dos           1   \n",
              "4                  ricktolledo           2   \n",
              "...                        ...         ...   \n",
              "9202  perspectiveinvestimentos           2   \n",
              "9203            eduardocolares           2   \n",
              "9204                 danielucm           2   \n",
              "9205          amgcapitalinvest           1   \n",
              "9206                 bfmarilia           0   \n",
              "\n",
              "                                          texto_tratado  \n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...  \n",
              "1     [btgpactual, with, makerepost, entender, impac...  \n",
              "2                                 [minuto, touro, ouro]  \n",
              "3                                                 [sim]  \n",
              "4         [querer, saber, banking, próprio, administro]  \n",
              "...                                                 ...  \n",
              "9202                            [excelente, explicação]  \n",
              "9203                    [atendar, telefone, amor, deus]  \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...  \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...  \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...  \n",
              "\n",
              "[9207 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59f8c3d1-5f08-4ad2-ad30-ef651595852d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>autor</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>texto_tratado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>winthegame_of</td>\n",
              "      <td>1</td>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marta_bego</td>\n",
              "      <td>1</td>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmviapiana</td>\n",
              "      <td>2</td>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vanilson_dos</td>\n",
              "      <td>1</td>\n",
              "      <td>[sim]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ricktolledo</td>\n",
              "      <td>2</td>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>perspectiveinvestimentos</td>\n",
              "      <td>2</td>\n",
              "      <td>[excelente, explicação]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>eduardocolares</td>\n",
              "      <td>2</td>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>danielucm</td>\n",
              "      <td>2</td>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>amgcapitalinvest</td>\n",
              "      <td>1</td>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>bfmarilia</td>\n",
              "      <td>0</td>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59f8c3d1-5f08-4ad2-ad30-ef651595852d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59f8c3d1-5f08-4ad2-ad30-ef651595852d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59f8c3d1-5f08-4ad2-ad30-ef651595852d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbow = '/content/drive/MyDrive/Módulo 6/Semana 5/cbow_s50/cbow_s50.txt'"
      ],
      "metadata": {
        "id": "8nzqODtZcsdF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cbow = KeyedVectors.load_word2vec_format(cbow)"
      ],
      "metadata": {
        "id": "ejOULae3dOeN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste isolado"
      ],
      "metadata": {
        "id": "G4jU0o6Ud7jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando o word2vec\n",
        "wordvec_test = model_cbow['projeto']\n",
        "\n",
        "wordvec_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib98bYExdQ09",
        "outputId": "0e01bd5e-f4ab-4d53-8ca6-b61a05093f20"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.074174, -0.152088,  0.086627, -0.224567,  0.362562,  0.130683,\n",
              "       -0.089179, -0.086973,  0.309501,  0.004112, -0.308202,  0.351789,\n",
              "       -0.477863,  0.050276,  0.213283,  0.159895, -0.285545, -0.08832 ,\n",
              "       -0.015449,  0.014816, -0.613861,  0.502556,  0.021688,  0.369492,\n",
              "        0.280691,  0.016868,  0.105584, -0.180754, -0.078456,  0.148032,\n",
              "        0.36293 , -0.011634,  0.412191, -0.009049,  0.010404,  0.131242,\n",
              "       -0.032483, -0.133067, -0.063802,  0.434015, -0.214768, -0.072132,\n",
              "        0.045601, -0.368866,  0.502808,  0.048293, -0.254894,  0.142581,\n",
              "       -0.075066,  0.015646], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição de função"
      ],
      "metadata": {
        "id": "XVpVpl42d9Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentence_vector(model, df):\n",
        "    sentence_table = []\n",
        "    for sentence in df['texto_tratado']:\n",
        "        word_vectors = [model[word] for word in sentence if word in model]\n",
        "        if len(word_vectors) > 0:\n",
        "            sentence_vector = sum(word_vectors) / len(word_vectors)\n",
        "        else:\n",
        "            sentence_vector = [None] * 100  # Cria uma lista de 100 elementos None\n",
        "        sentence_table.append((sentence, *sentence_vector[:50]))  # Adiciona apenas os primeiros 50 elementos do vetor\n",
        "\n",
        "    column_labels = ['Frase']\n",
        "    for i in range(50):\n",
        "        column_labels.append(f'Vetor{i+1}')\n",
        "    df_vec = pd.DataFrame(sentence_table, columns=column_labels)\n",
        "\n",
        "    df[\"sentimentoNumerico\"] = df[\"sentimento\"].replace({'NEGATIVE': -1, 'POSITIVE': 1, 'NEUTRAL': 0})\n",
        "\n",
        "    # Definir o índice do DataFrame df_vec como o mesmo índice de df_processada['sentimentoNumerico']\n",
        "    df_vec.set_index(df[\"sentimentoNumerico\"].index, inplace=True)\n",
        "\n",
        "    df_vec['sentimento'] = df[\"sentimentoNumerico\"]\n",
        "    df_vec = df_vec.dropna()\n",
        "\n",
        "    return df_vec"
      ],
      "metadata": {
        "id": "iI_Gq3b3dVuk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste de funções"
      ],
      "metadata": {
        "id": "3k0a2PQ3eABM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_vec = create_sentence_vector(model_cbow, df)\n",
        "df_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "KFlOnmx7eBlj",
        "outputId": "eec123ed-c386-4c08-853f-0c036c173544"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Frase    Vetor1    Vetor2  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...  0.213634 -0.129877   \n",
              "1     [btgpactual, with, makerepost, entender, impac...  0.222697 -0.124886   \n",
              "2                                 [minuto, touro, ouro]  0.265227 -0.068285   \n",
              "3                                                 [sim]  0.166258 -0.029796   \n",
              "4         [querer, saber, banking, próprio, administro]  0.187512 -0.183612   \n",
              "...                                                 ...       ...       ...   \n",
              "9202                            [excelente, explicação]  0.190917 -0.133475   \n",
              "9203                    [atendar, telefone, amor, deus]  0.188641 -0.119377   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...  0.215474 -0.137852   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...  0.219393 -0.129317   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...  0.225402 -0.137580   \n",
              "\n",
              "        Vetor3    Vetor4    Vetor5    Vetor6    Vetor7    Vetor8    Vetor9  \\\n",
              "0     0.241601 -0.075002 -0.015629  0.206194  0.072658  0.055472  0.061554   \n",
              "1     0.213157 -0.059091 -0.010530  0.201566  0.071898  0.033920  0.059524   \n",
              "2     0.152235 -0.044329 -0.102729  0.141353  0.092800  0.113174  0.015783   \n",
              "3     0.204045 -0.297490  0.046077  0.140763  0.035251 -0.174491  0.211817   \n",
              "4     0.300155 -0.052422 -0.034717  0.232278  0.058778  0.084289  0.088006   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.241675 -0.053180  0.067256  0.201138  0.034109 -0.078718 -0.066131   \n",
              "9203  0.199339 -0.105448  0.023176  0.178837  0.069476 -0.004494  0.034710   \n",
              "9204  0.223206 -0.072183 -0.013213  0.205186  0.063497  0.039164  0.070273   \n",
              "9205  0.239226 -0.064735 -0.025696  0.224218  0.070732  0.042386  0.040706   \n",
              "9206  0.274046 -0.044282  0.008441  0.249057  0.043162  0.080058  0.049930   \n",
              "\n",
              "      ...   Vetor42   Vetor43   Vetor44   Vetor45   Vetor46   Vetor47  \\\n",
              "0     ...  0.024361 -0.111328  0.157674  0.094309 -0.047458  0.157365   \n",
              "1     ...  0.008988 -0.079109  0.159296  0.085387 -0.008607  0.158519   \n",
              "2     ...  0.078032 -0.202677  0.155750  0.062291  0.007038  0.134573   \n",
              "3     ...  0.065839 -0.092451  0.308218 -0.034692 -0.032851 -0.028724   \n",
              "4     ...  0.097538 -0.161461  0.196748  0.088577 -0.080884  0.167507   \n",
              "...   ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  ... -0.082151  0.016113  0.154861  0.068700 -0.004302  0.079717   \n",
              "9203  ...  0.034035 -0.126673  0.165176  0.080313 -0.024160  0.118848   \n",
              "9204  ...  0.034706 -0.097793  0.177275  0.090335 -0.047405  0.154374   \n",
              "9205  ...  0.025414 -0.108338  0.160880  0.092846 -0.032266  0.151619   \n",
              "9206  ...  0.007607 -0.097939  0.163142  0.100946 -0.034086  0.136629   \n",
              "\n",
              "       Vetor48   Vetor49   Vetor50  sentimento  \n",
              "0    -0.033920  0.022211  0.182153           1  \n",
              "1    -0.022680  0.031107  0.189521           1  \n",
              "2     0.014635  0.034189  0.345674           2  \n",
              "3    -0.068701  0.011158  0.258413           1  \n",
              "4    -0.049984 -0.000942  0.187811           2  \n",
              "...        ...       ...       ...         ...  \n",
              "9202 -0.028388 -0.017448  0.188785           2  \n",
              "9203 -0.003502  0.087053  0.215656           2  \n",
              "9204 -0.028906  0.023713  0.179591           2  \n",
              "9205 -0.023750  0.028080  0.191956           1  \n",
              "9206 -0.024904  0.030681  0.170319           0  \n",
              "\n",
              "[9207 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d4dfdde-c6d6-459b-be48-eff107e52123\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frase</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>Vetor8</th>\n",
              "      <th>Vetor9</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor42</th>\n",
              "      <th>Vetor43</th>\n",
              "      <th>Vetor44</th>\n",
              "      <th>Vetor45</th>\n",
              "      <th>Vetor46</th>\n",
              "      <th>Vetor47</th>\n",
              "      <th>Vetor48</th>\n",
              "      <th>Vetor49</th>\n",
              "      <th>Vetor50</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>0.213634</td>\n",
              "      <td>-0.129877</td>\n",
              "      <td>0.241601</td>\n",
              "      <td>-0.075002</td>\n",
              "      <td>-0.015629</td>\n",
              "      <td>0.206194</td>\n",
              "      <td>0.072658</td>\n",
              "      <td>0.055472</td>\n",
              "      <td>0.061554</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024361</td>\n",
              "      <td>-0.111328</td>\n",
              "      <td>0.157674</td>\n",
              "      <td>0.094309</td>\n",
              "      <td>-0.047458</td>\n",
              "      <td>0.157365</td>\n",
              "      <td>-0.033920</td>\n",
              "      <td>0.022211</td>\n",
              "      <td>0.182153</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>0.222697</td>\n",
              "      <td>-0.124886</td>\n",
              "      <td>0.213157</td>\n",
              "      <td>-0.059091</td>\n",
              "      <td>-0.010530</td>\n",
              "      <td>0.201566</td>\n",
              "      <td>0.071898</td>\n",
              "      <td>0.033920</td>\n",
              "      <td>0.059524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>-0.079109</td>\n",
              "      <td>0.159296</td>\n",
              "      <td>0.085387</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>0.158519</td>\n",
              "      <td>-0.022680</td>\n",
              "      <td>0.031107</td>\n",
              "      <td>0.189521</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>0.265227</td>\n",
              "      <td>-0.068285</td>\n",
              "      <td>0.152235</td>\n",
              "      <td>-0.044329</td>\n",
              "      <td>-0.102729</td>\n",
              "      <td>0.141353</td>\n",
              "      <td>0.092800</td>\n",
              "      <td>0.113174</td>\n",
              "      <td>0.015783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078032</td>\n",
              "      <td>-0.202677</td>\n",
              "      <td>0.155750</td>\n",
              "      <td>0.062291</td>\n",
              "      <td>0.007038</td>\n",
              "      <td>0.134573</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.345674</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sim]</td>\n",
              "      <td>0.166258</td>\n",
              "      <td>-0.029796</td>\n",
              "      <td>0.204045</td>\n",
              "      <td>-0.297490</td>\n",
              "      <td>0.046077</td>\n",
              "      <td>0.140763</td>\n",
              "      <td>0.035251</td>\n",
              "      <td>-0.174491</td>\n",
              "      <td>0.211817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065839</td>\n",
              "      <td>-0.092451</td>\n",
              "      <td>0.308218</td>\n",
              "      <td>-0.034692</td>\n",
              "      <td>-0.032851</td>\n",
              "      <td>-0.028724</td>\n",
              "      <td>-0.068701</td>\n",
              "      <td>0.011158</td>\n",
              "      <td>0.258413</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>0.187512</td>\n",
              "      <td>-0.183612</td>\n",
              "      <td>0.300155</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.034717</td>\n",
              "      <td>0.232278</td>\n",
              "      <td>0.058778</td>\n",
              "      <td>0.084289</td>\n",
              "      <td>0.088006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097538</td>\n",
              "      <td>-0.161461</td>\n",
              "      <td>0.196748</td>\n",
              "      <td>0.088577</td>\n",
              "      <td>-0.080884</td>\n",
              "      <td>0.167507</td>\n",
              "      <td>-0.049984</td>\n",
              "      <td>-0.000942</td>\n",
              "      <td>0.187811</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>0.190917</td>\n",
              "      <td>-0.133475</td>\n",
              "      <td>0.241675</td>\n",
              "      <td>-0.053180</td>\n",
              "      <td>0.067256</td>\n",
              "      <td>0.201138</td>\n",
              "      <td>0.034109</td>\n",
              "      <td>-0.078718</td>\n",
              "      <td>-0.066131</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.082151</td>\n",
              "      <td>0.016113</td>\n",
              "      <td>0.154861</td>\n",
              "      <td>0.068700</td>\n",
              "      <td>-0.004302</td>\n",
              "      <td>0.079717</td>\n",
              "      <td>-0.028388</td>\n",
              "      <td>-0.017448</td>\n",
              "      <td>0.188785</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>0.188641</td>\n",
              "      <td>-0.119377</td>\n",
              "      <td>0.199339</td>\n",
              "      <td>-0.105448</td>\n",
              "      <td>0.023176</td>\n",
              "      <td>0.178837</td>\n",
              "      <td>0.069476</td>\n",
              "      <td>-0.004494</td>\n",
              "      <td>0.034710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034035</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>0.165176</td>\n",
              "      <td>0.080313</td>\n",
              "      <td>-0.024160</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>-0.003502</td>\n",
              "      <td>0.087053</td>\n",
              "      <td>0.215656</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>0.215474</td>\n",
              "      <td>-0.137852</td>\n",
              "      <td>0.223206</td>\n",
              "      <td>-0.072183</td>\n",
              "      <td>-0.013213</td>\n",
              "      <td>0.205186</td>\n",
              "      <td>0.063497</td>\n",
              "      <td>0.039164</td>\n",
              "      <td>0.070273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034706</td>\n",
              "      <td>-0.097793</td>\n",
              "      <td>0.177275</td>\n",
              "      <td>0.090335</td>\n",
              "      <td>-0.047405</td>\n",
              "      <td>0.154374</td>\n",
              "      <td>-0.028906</td>\n",
              "      <td>0.023713</td>\n",
              "      <td>0.179591</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>0.219393</td>\n",
              "      <td>-0.129317</td>\n",
              "      <td>0.239226</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>-0.025696</td>\n",
              "      <td>0.224218</td>\n",
              "      <td>0.070732</td>\n",
              "      <td>0.042386</td>\n",
              "      <td>0.040706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025414</td>\n",
              "      <td>-0.108338</td>\n",
              "      <td>0.160880</td>\n",
              "      <td>0.092846</td>\n",
              "      <td>-0.032266</td>\n",
              "      <td>0.151619</td>\n",
              "      <td>-0.023750</td>\n",
              "      <td>0.028080</td>\n",
              "      <td>0.191956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0.225402</td>\n",
              "      <td>-0.137580</td>\n",
              "      <td>0.274046</td>\n",
              "      <td>-0.044282</td>\n",
              "      <td>0.008441</td>\n",
              "      <td>0.249057</td>\n",
              "      <td>0.043162</td>\n",
              "      <td>0.080058</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007607</td>\n",
              "      <td>-0.097939</td>\n",
              "      <td>0.163142</td>\n",
              "      <td>0.100946</td>\n",
              "      <td>-0.034086</td>\n",
              "      <td>0.136629</td>\n",
              "      <td>-0.024904</td>\n",
              "      <td>0.030681</td>\n",
              "      <td>0.170319</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d4dfdde-c6d6-459b-be48-eff107e52123')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d4dfdde-c6d6-459b-be48-eff107e52123 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d4dfdde-c6d6-459b-be48-eff107e52123');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_vec.to_csv('Word2Vec_Cbow_modelo_treinado',encoding='utf-8', index=False, header=True)"
      ],
      "metadata": {
        "id": "Z0GHiMo0fyUG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Naive Bayes + Word2Vec com CBOW"
      ],
      "metadata": {
        "id": "prPzkLeviBp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "vQqytS9KiC1G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label.fit(df_vec['sentimento'])\n",
        "df_vec['sentimento'] = label.transform(df_vec['sentimento'])"
      ],
      "metadata": {
        "id": "hNo9-z7Yiaa3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_vec = df_vec.dropna()\n",
        "df_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "ETQSLjTViq0n",
        "outputId": "992b8526-bc8c-461f-84aa-0b6eb9b131d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Frase    Vetor1    Vetor2  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...  0.213634 -0.129877   \n",
              "1     [btgpactual, with, makerepost, entender, impac...  0.222697 -0.124886   \n",
              "2                                 [minuto, touro, ouro]  0.265227 -0.068285   \n",
              "3                                                 [sim]  0.166258 -0.029796   \n",
              "4         [querer, saber, banking, próprio, administro]  0.187512 -0.183612   \n",
              "...                                                 ...       ...       ...   \n",
              "9202                            [excelente, explicação]  0.190917 -0.133475   \n",
              "9203                    [atendar, telefone, amor, deus]  0.188641 -0.119377   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...  0.215474 -0.137852   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...  0.219393 -0.129317   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...  0.225402 -0.137580   \n",
              "\n",
              "        Vetor3    Vetor4    Vetor5    Vetor6    Vetor7    Vetor8    Vetor9  \\\n",
              "0     0.241601 -0.075002 -0.015629  0.206194  0.072658  0.055472  0.061554   \n",
              "1     0.213157 -0.059091 -0.010530  0.201566  0.071898  0.033920  0.059524   \n",
              "2     0.152235 -0.044329 -0.102729  0.141353  0.092800  0.113174  0.015783   \n",
              "3     0.204045 -0.297490  0.046077  0.140763  0.035251 -0.174491  0.211817   \n",
              "4     0.300155 -0.052422 -0.034717  0.232278  0.058778  0.084289  0.088006   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.241675 -0.053180  0.067256  0.201138  0.034109 -0.078718 -0.066131   \n",
              "9203  0.199339 -0.105448  0.023176  0.178837  0.069476 -0.004494  0.034710   \n",
              "9204  0.223206 -0.072183 -0.013213  0.205186  0.063497  0.039164  0.070273   \n",
              "9205  0.239226 -0.064735 -0.025696  0.224218  0.070732  0.042386  0.040706   \n",
              "9206  0.274046 -0.044282  0.008441  0.249057  0.043162  0.080058  0.049930   \n",
              "\n",
              "      ...   Vetor42   Vetor43   Vetor44   Vetor45   Vetor46   Vetor47  \\\n",
              "0     ...  0.024361 -0.111328  0.157674  0.094309 -0.047458  0.157365   \n",
              "1     ...  0.008988 -0.079109  0.159296  0.085387 -0.008607  0.158519   \n",
              "2     ...  0.078032 -0.202677  0.155750  0.062291  0.007038  0.134573   \n",
              "3     ...  0.065839 -0.092451  0.308218 -0.034692 -0.032851 -0.028724   \n",
              "4     ...  0.097538 -0.161461  0.196748  0.088577 -0.080884  0.167507   \n",
              "...   ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  ... -0.082151  0.016113  0.154861  0.068700 -0.004302  0.079717   \n",
              "9203  ...  0.034035 -0.126673  0.165176  0.080313 -0.024160  0.118848   \n",
              "9204  ...  0.034706 -0.097793  0.177275  0.090335 -0.047405  0.154374   \n",
              "9205  ...  0.025414 -0.108338  0.160880  0.092846 -0.032266  0.151619   \n",
              "9206  ...  0.007607 -0.097939  0.163142  0.100946 -0.034086  0.136629   \n",
              "\n",
              "       Vetor48   Vetor49   Vetor50  sentimento  \n",
              "0    -0.033920  0.022211  0.182153           1  \n",
              "1    -0.022680  0.031107  0.189521           1  \n",
              "2     0.014635  0.034189  0.345674           2  \n",
              "3    -0.068701  0.011158  0.258413           1  \n",
              "4    -0.049984 -0.000942  0.187811           2  \n",
              "...        ...       ...       ...         ...  \n",
              "9202 -0.028388 -0.017448  0.188785           2  \n",
              "9203 -0.003502  0.087053  0.215656           2  \n",
              "9204 -0.028906  0.023713  0.179591           2  \n",
              "9205 -0.023750  0.028080  0.191956           1  \n",
              "9206 -0.024904  0.030681  0.170319           0  \n",
              "\n",
              "[9207 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a61a19e8-387a-4e2c-ab5e-fab8cc327332\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frase</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>Vetor8</th>\n",
              "      <th>Vetor9</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor42</th>\n",
              "      <th>Vetor43</th>\n",
              "      <th>Vetor44</th>\n",
              "      <th>Vetor45</th>\n",
              "      <th>Vetor46</th>\n",
              "      <th>Vetor47</th>\n",
              "      <th>Vetor48</th>\n",
              "      <th>Vetor49</th>\n",
              "      <th>Vetor50</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>0.213634</td>\n",
              "      <td>-0.129877</td>\n",
              "      <td>0.241601</td>\n",
              "      <td>-0.075002</td>\n",
              "      <td>-0.015629</td>\n",
              "      <td>0.206194</td>\n",
              "      <td>0.072658</td>\n",
              "      <td>0.055472</td>\n",
              "      <td>0.061554</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024361</td>\n",
              "      <td>-0.111328</td>\n",
              "      <td>0.157674</td>\n",
              "      <td>0.094309</td>\n",
              "      <td>-0.047458</td>\n",
              "      <td>0.157365</td>\n",
              "      <td>-0.033920</td>\n",
              "      <td>0.022211</td>\n",
              "      <td>0.182153</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>0.222697</td>\n",
              "      <td>-0.124886</td>\n",
              "      <td>0.213157</td>\n",
              "      <td>-0.059091</td>\n",
              "      <td>-0.010530</td>\n",
              "      <td>0.201566</td>\n",
              "      <td>0.071898</td>\n",
              "      <td>0.033920</td>\n",
              "      <td>0.059524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>-0.079109</td>\n",
              "      <td>0.159296</td>\n",
              "      <td>0.085387</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>0.158519</td>\n",
              "      <td>-0.022680</td>\n",
              "      <td>0.031107</td>\n",
              "      <td>0.189521</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>0.265227</td>\n",
              "      <td>-0.068285</td>\n",
              "      <td>0.152235</td>\n",
              "      <td>-0.044329</td>\n",
              "      <td>-0.102729</td>\n",
              "      <td>0.141353</td>\n",
              "      <td>0.092800</td>\n",
              "      <td>0.113174</td>\n",
              "      <td>0.015783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078032</td>\n",
              "      <td>-0.202677</td>\n",
              "      <td>0.155750</td>\n",
              "      <td>0.062291</td>\n",
              "      <td>0.007038</td>\n",
              "      <td>0.134573</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.345674</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sim]</td>\n",
              "      <td>0.166258</td>\n",
              "      <td>-0.029796</td>\n",
              "      <td>0.204045</td>\n",
              "      <td>-0.297490</td>\n",
              "      <td>0.046077</td>\n",
              "      <td>0.140763</td>\n",
              "      <td>0.035251</td>\n",
              "      <td>-0.174491</td>\n",
              "      <td>0.211817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065839</td>\n",
              "      <td>-0.092451</td>\n",
              "      <td>0.308218</td>\n",
              "      <td>-0.034692</td>\n",
              "      <td>-0.032851</td>\n",
              "      <td>-0.028724</td>\n",
              "      <td>-0.068701</td>\n",
              "      <td>0.011158</td>\n",
              "      <td>0.258413</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>0.187512</td>\n",
              "      <td>-0.183612</td>\n",
              "      <td>0.300155</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.034717</td>\n",
              "      <td>0.232278</td>\n",
              "      <td>0.058778</td>\n",
              "      <td>0.084289</td>\n",
              "      <td>0.088006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097538</td>\n",
              "      <td>-0.161461</td>\n",
              "      <td>0.196748</td>\n",
              "      <td>0.088577</td>\n",
              "      <td>-0.080884</td>\n",
              "      <td>0.167507</td>\n",
              "      <td>-0.049984</td>\n",
              "      <td>-0.000942</td>\n",
              "      <td>0.187811</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>0.190917</td>\n",
              "      <td>-0.133475</td>\n",
              "      <td>0.241675</td>\n",
              "      <td>-0.053180</td>\n",
              "      <td>0.067256</td>\n",
              "      <td>0.201138</td>\n",
              "      <td>0.034109</td>\n",
              "      <td>-0.078718</td>\n",
              "      <td>-0.066131</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.082151</td>\n",
              "      <td>0.016113</td>\n",
              "      <td>0.154861</td>\n",
              "      <td>0.068700</td>\n",
              "      <td>-0.004302</td>\n",
              "      <td>0.079717</td>\n",
              "      <td>-0.028388</td>\n",
              "      <td>-0.017448</td>\n",
              "      <td>0.188785</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>0.188641</td>\n",
              "      <td>-0.119377</td>\n",
              "      <td>0.199339</td>\n",
              "      <td>-0.105448</td>\n",
              "      <td>0.023176</td>\n",
              "      <td>0.178837</td>\n",
              "      <td>0.069476</td>\n",
              "      <td>-0.004494</td>\n",
              "      <td>0.034710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034035</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>0.165176</td>\n",
              "      <td>0.080313</td>\n",
              "      <td>-0.024160</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>-0.003502</td>\n",
              "      <td>0.087053</td>\n",
              "      <td>0.215656</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>0.215474</td>\n",
              "      <td>-0.137852</td>\n",
              "      <td>0.223206</td>\n",
              "      <td>-0.072183</td>\n",
              "      <td>-0.013213</td>\n",
              "      <td>0.205186</td>\n",
              "      <td>0.063497</td>\n",
              "      <td>0.039164</td>\n",
              "      <td>0.070273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034706</td>\n",
              "      <td>-0.097793</td>\n",
              "      <td>0.177275</td>\n",
              "      <td>0.090335</td>\n",
              "      <td>-0.047405</td>\n",
              "      <td>0.154374</td>\n",
              "      <td>-0.028906</td>\n",
              "      <td>0.023713</td>\n",
              "      <td>0.179591</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>0.219393</td>\n",
              "      <td>-0.129317</td>\n",
              "      <td>0.239226</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>-0.025696</td>\n",
              "      <td>0.224218</td>\n",
              "      <td>0.070732</td>\n",
              "      <td>0.042386</td>\n",
              "      <td>0.040706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025414</td>\n",
              "      <td>-0.108338</td>\n",
              "      <td>0.160880</td>\n",
              "      <td>0.092846</td>\n",
              "      <td>-0.032266</td>\n",
              "      <td>0.151619</td>\n",
              "      <td>-0.023750</td>\n",
              "      <td>0.028080</td>\n",
              "      <td>0.191956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0.225402</td>\n",
              "      <td>-0.137580</td>\n",
              "      <td>0.274046</td>\n",
              "      <td>-0.044282</td>\n",
              "      <td>0.008441</td>\n",
              "      <td>0.249057</td>\n",
              "      <td>0.043162</td>\n",
              "      <td>0.080058</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007607</td>\n",
              "      <td>-0.097939</td>\n",
              "      <td>0.163142</td>\n",
              "      <td>0.100946</td>\n",
              "      <td>-0.034086</td>\n",
              "      <td>0.136629</td>\n",
              "      <td>-0.024904</td>\n",
              "      <td>0.030681</td>\n",
              "      <td>0.170319</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a61a19e8-387a-4e2c-ab5e-fab8cc327332')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a61a19e8-387a-4e2c-ab5e-fab8cc327332 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a61a19e8-387a-4e2c-ab5e-fab8cc327332');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separando Treino e Teste"
      ],
      "metadata": {
        "id": "bAPCRhOKiwX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = df_vec['sentimento']"
      ],
      "metadata": {
        "id": "mNPlS_2TitHe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = df_vec.iloc[:,1:50]"
      ],
      "metadata": {
        "id": "keRvRtXfi73e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "C0avdw6TjC1W",
        "outputId": "eedd0ff0-9a29-44f1-abc3-8ae43668b376"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Vetor1    Vetor2    Vetor3    Vetor4    Vetor5    Vetor6    Vetor7  \\\n",
              "0     0.213634 -0.129877  0.241601 -0.075002 -0.015629  0.206194  0.072658   \n",
              "1     0.222697 -0.124886  0.213157 -0.059091 -0.010530  0.201566  0.071898   \n",
              "2     0.265227 -0.068285  0.152235 -0.044329 -0.102729  0.141353  0.092800   \n",
              "3     0.166258 -0.029796  0.204045 -0.297490  0.046077  0.140763  0.035251   \n",
              "4     0.187512 -0.183612  0.300155 -0.052422 -0.034717  0.232278  0.058778   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.190917 -0.133475  0.241675 -0.053180  0.067256  0.201138  0.034109   \n",
              "9203  0.188641 -0.119377  0.199339 -0.105448  0.023176  0.178837  0.069476   \n",
              "9204  0.215474 -0.137852  0.223206 -0.072183 -0.013213  0.205186  0.063497   \n",
              "9205  0.219393 -0.129317  0.239226 -0.064735 -0.025696  0.224218  0.070732   \n",
              "9206  0.225402 -0.137580  0.274046 -0.044282  0.008441  0.249057  0.043162   \n",
              "\n",
              "        Vetor8    Vetor9   Vetor10  ...   Vetor40   Vetor41   Vetor42  \\\n",
              "0     0.055472  0.061554  0.170172  ...  0.074627 -0.270438  0.024361   \n",
              "1     0.033920  0.059524  0.164536  ...  0.086584 -0.301574  0.008988   \n",
              "2     0.113174  0.015783  0.202198  ... -0.008447 -0.193025  0.078032   \n",
              "3    -0.174491  0.211817  0.288314  ...  0.183434 -0.415105  0.065839   \n",
              "4     0.084289  0.088006  0.148424  ...  0.046667 -0.247744  0.097538   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9202 -0.078718 -0.066131  0.187608  ...  0.014565 -0.321192 -0.082151   \n",
              "9203 -0.004494  0.034710  0.150081  ...  0.071114 -0.194663  0.034035   \n",
              "9204  0.039164  0.070273  0.172185  ...  0.081652 -0.300155  0.034706   \n",
              "9205  0.042386  0.040706  0.154811  ...  0.063415 -0.258450  0.025414   \n",
              "9206  0.080058  0.049930  0.108385  ...  0.085501 -0.235024  0.007607   \n",
              "\n",
              "       Vetor43   Vetor44   Vetor45   Vetor46   Vetor47   Vetor48   Vetor49  \n",
              "0    -0.111328  0.157674  0.094309 -0.047458  0.157365 -0.033920  0.022211  \n",
              "1    -0.079109  0.159296  0.085387 -0.008607  0.158519 -0.022680  0.031107  \n",
              "2    -0.202677  0.155750  0.062291  0.007038  0.134573  0.014635  0.034189  \n",
              "3    -0.092451  0.308218 -0.034692 -0.032851 -0.028724 -0.068701  0.011158  \n",
              "4    -0.161461  0.196748  0.088577 -0.080884  0.167507 -0.049984 -0.000942  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "9202  0.016113  0.154861  0.068700 -0.004302  0.079717 -0.028388 -0.017448  \n",
              "9203 -0.126673  0.165176  0.080313 -0.024160  0.118848 -0.003502  0.087053  \n",
              "9204 -0.097793  0.177275  0.090335 -0.047405  0.154374 -0.028906  0.023713  \n",
              "9205 -0.108338  0.160880  0.092846 -0.032266  0.151619 -0.023750  0.028080  \n",
              "9206 -0.097939  0.163142  0.100946 -0.034086  0.136629 -0.024904  0.030681  \n",
              "\n",
              "[9207 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2883ea07-1ddf-465a-ae5c-4d23f2a0eb09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>Vetor8</th>\n",
              "      <th>Vetor9</th>\n",
              "      <th>Vetor10</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor40</th>\n",
              "      <th>Vetor41</th>\n",
              "      <th>Vetor42</th>\n",
              "      <th>Vetor43</th>\n",
              "      <th>Vetor44</th>\n",
              "      <th>Vetor45</th>\n",
              "      <th>Vetor46</th>\n",
              "      <th>Vetor47</th>\n",
              "      <th>Vetor48</th>\n",
              "      <th>Vetor49</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.213634</td>\n",
              "      <td>-0.129877</td>\n",
              "      <td>0.241601</td>\n",
              "      <td>-0.075002</td>\n",
              "      <td>-0.015629</td>\n",
              "      <td>0.206194</td>\n",
              "      <td>0.072658</td>\n",
              "      <td>0.055472</td>\n",
              "      <td>0.061554</td>\n",
              "      <td>0.170172</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>-0.270438</td>\n",
              "      <td>0.024361</td>\n",
              "      <td>-0.111328</td>\n",
              "      <td>0.157674</td>\n",
              "      <td>0.094309</td>\n",
              "      <td>-0.047458</td>\n",
              "      <td>0.157365</td>\n",
              "      <td>-0.033920</td>\n",
              "      <td>0.022211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.222697</td>\n",
              "      <td>-0.124886</td>\n",
              "      <td>0.213157</td>\n",
              "      <td>-0.059091</td>\n",
              "      <td>-0.010530</td>\n",
              "      <td>0.201566</td>\n",
              "      <td>0.071898</td>\n",
              "      <td>0.033920</td>\n",
              "      <td>0.059524</td>\n",
              "      <td>0.164536</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086584</td>\n",
              "      <td>-0.301574</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>-0.079109</td>\n",
              "      <td>0.159296</td>\n",
              "      <td>0.085387</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>0.158519</td>\n",
              "      <td>-0.022680</td>\n",
              "      <td>0.031107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.265227</td>\n",
              "      <td>-0.068285</td>\n",
              "      <td>0.152235</td>\n",
              "      <td>-0.044329</td>\n",
              "      <td>-0.102729</td>\n",
              "      <td>0.141353</td>\n",
              "      <td>0.092800</td>\n",
              "      <td>0.113174</td>\n",
              "      <td>0.015783</td>\n",
              "      <td>0.202198</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008447</td>\n",
              "      <td>-0.193025</td>\n",
              "      <td>0.078032</td>\n",
              "      <td>-0.202677</td>\n",
              "      <td>0.155750</td>\n",
              "      <td>0.062291</td>\n",
              "      <td>0.007038</td>\n",
              "      <td>0.134573</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.034189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.166258</td>\n",
              "      <td>-0.029796</td>\n",
              "      <td>0.204045</td>\n",
              "      <td>-0.297490</td>\n",
              "      <td>0.046077</td>\n",
              "      <td>0.140763</td>\n",
              "      <td>0.035251</td>\n",
              "      <td>-0.174491</td>\n",
              "      <td>0.211817</td>\n",
              "      <td>0.288314</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183434</td>\n",
              "      <td>-0.415105</td>\n",
              "      <td>0.065839</td>\n",
              "      <td>-0.092451</td>\n",
              "      <td>0.308218</td>\n",
              "      <td>-0.034692</td>\n",
              "      <td>-0.032851</td>\n",
              "      <td>-0.028724</td>\n",
              "      <td>-0.068701</td>\n",
              "      <td>0.011158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.187512</td>\n",
              "      <td>-0.183612</td>\n",
              "      <td>0.300155</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.034717</td>\n",
              "      <td>0.232278</td>\n",
              "      <td>0.058778</td>\n",
              "      <td>0.084289</td>\n",
              "      <td>0.088006</td>\n",
              "      <td>0.148424</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046667</td>\n",
              "      <td>-0.247744</td>\n",
              "      <td>0.097538</td>\n",
              "      <td>-0.161461</td>\n",
              "      <td>0.196748</td>\n",
              "      <td>0.088577</td>\n",
              "      <td>-0.080884</td>\n",
              "      <td>0.167507</td>\n",
              "      <td>-0.049984</td>\n",
              "      <td>-0.000942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>0.190917</td>\n",
              "      <td>-0.133475</td>\n",
              "      <td>0.241675</td>\n",
              "      <td>-0.053180</td>\n",
              "      <td>0.067256</td>\n",
              "      <td>0.201138</td>\n",
              "      <td>0.034109</td>\n",
              "      <td>-0.078718</td>\n",
              "      <td>-0.066131</td>\n",
              "      <td>0.187608</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014565</td>\n",
              "      <td>-0.321192</td>\n",
              "      <td>-0.082151</td>\n",
              "      <td>0.016113</td>\n",
              "      <td>0.154861</td>\n",
              "      <td>0.068700</td>\n",
              "      <td>-0.004302</td>\n",
              "      <td>0.079717</td>\n",
              "      <td>-0.028388</td>\n",
              "      <td>-0.017448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>0.188641</td>\n",
              "      <td>-0.119377</td>\n",
              "      <td>0.199339</td>\n",
              "      <td>-0.105448</td>\n",
              "      <td>0.023176</td>\n",
              "      <td>0.178837</td>\n",
              "      <td>0.069476</td>\n",
              "      <td>-0.004494</td>\n",
              "      <td>0.034710</td>\n",
              "      <td>0.150081</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071114</td>\n",
              "      <td>-0.194663</td>\n",
              "      <td>0.034035</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>0.165176</td>\n",
              "      <td>0.080313</td>\n",
              "      <td>-0.024160</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>-0.003502</td>\n",
              "      <td>0.087053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>0.215474</td>\n",
              "      <td>-0.137852</td>\n",
              "      <td>0.223206</td>\n",
              "      <td>-0.072183</td>\n",
              "      <td>-0.013213</td>\n",
              "      <td>0.205186</td>\n",
              "      <td>0.063497</td>\n",
              "      <td>0.039164</td>\n",
              "      <td>0.070273</td>\n",
              "      <td>0.172185</td>\n",
              "      <td>...</td>\n",
              "      <td>0.081652</td>\n",
              "      <td>-0.300155</td>\n",
              "      <td>0.034706</td>\n",
              "      <td>-0.097793</td>\n",
              "      <td>0.177275</td>\n",
              "      <td>0.090335</td>\n",
              "      <td>-0.047405</td>\n",
              "      <td>0.154374</td>\n",
              "      <td>-0.028906</td>\n",
              "      <td>0.023713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>0.219393</td>\n",
              "      <td>-0.129317</td>\n",
              "      <td>0.239226</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>-0.025696</td>\n",
              "      <td>0.224218</td>\n",
              "      <td>0.070732</td>\n",
              "      <td>0.042386</td>\n",
              "      <td>0.040706</td>\n",
              "      <td>0.154811</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063415</td>\n",
              "      <td>-0.258450</td>\n",
              "      <td>0.025414</td>\n",
              "      <td>-0.108338</td>\n",
              "      <td>0.160880</td>\n",
              "      <td>0.092846</td>\n",
              "      <td>-0.032266</td>\n",
              "      <td>0.151619</td>\n",
              "      <td>-0.023750</td>\n",
              "      <td>0.028080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>0.225402</td>\n",
              "      <td>-0.137580</td>\n",
              "      <td>0.274046</td>\n",
              "      <td>-0.044282</td>\n",
              "      <td>0.008441</td>\n",
              "      <td>0.249057</td>\n",
              "      <td>0.043162</td>\n",
              "      <td>0.080058</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>0.108385</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085501</td>\n",
              "      <td>-0.235024</td>\n",
              "      <td>0.007607</td>\n",
              "      <td>-0.097939</td>\n",
              "      <td>0.163142</td>\n",
              "      <td>0.100946</td>\n",
              "      <td>-0.034086</td>\n",
              "      <td>0.136629</td>\n",
              "      <td>-0.024904</td>\n",
              "      <td>0.030681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 49 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2883ea07-1ddf-465a-ae5c-4d23f2a0eb09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2883ea07-1ddf-465a-ae5c-4d23f2a0eb09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2883ea07-1ddf-465a-ae5c-4d23f2a0eb09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zsSTEpdkjFBe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do modelo "
      ],
      "metadata": {
        "id": "L8lToFKbjXPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GaussianNB()\n",
        "\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5kpZIbzjUYt",
        "outputId": "bf4319fe-4486-4851-ab96-cbc573030d9d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.74      0.42       386\n",
            "           1       0.74      0.46      0.56       844\n",
            "           2       0.34      0.20      0.25       612\n",
            "\n",
            "    accuracy                           0.43      1842\n",
            "   macro avg       0.46      0.46      0.41      1842\n",
            "weighted avg       0.51      0.43      0.43      1842\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_score = accuracy_score(y_test, Y_pred)\n",
        "format_output = \"{:.2%}\".format(acc_score)\n",
        "print(\"Precisão final de :\",format_output) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJrPhaqsjxum",
        "outputId": "fa345ca6-4d54-4cb7-fbdb-91b5f698994f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão final de : 42.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Word2Vec com embedding layer"
      ],
      "metadata": {
        "id": "waBVgg875A8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição de função"
      ],
      "metadata": {
        "id": "jNNdngzMfudo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Função que treina o modelo Word2Vec no corpus do dataframe\n",
        "def train_word2vec(df, column_name):\n",
        "    # Obtém as frases tokenizadas\n",
        "    sentences = df[column_name].tolist()\n",
        "    \n",
        "    # Treina o modelo Word2Vec\n",
        "    model = Word2Vec(sentences, min_count=1)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "X_Wjh3oW5MkB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função que define os vetores para cada palavra do vocabulario\n",
        "def get_word_vectors(model, sentence):\n",
        "    vectors = []\n",
        "    for word in sentence:\n",
        "        if word in model.wv:\n",
        "            vectors.append(model.wv[word]) # Append na lista de vetores\n",
        "    if vectors:\n",
        "        return np.sum(vectors, axis=0)/len(sentence) # Soma dos vetores para cada frase\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "# Criação do dataframe de vetores para cada frase\n",
        "def create_word2vec_dataframe(df, column_name, model):\n",
        "    sentences = df[column_name].tolist()\n",
        "    vectors = [get_word_vectors(model, sentence) for sentence in sentences] # Itera para cada frase um vetor\n",
        "    # Criação do dataframe\n",
        "    df_vectors = pd.DataFrame(vectors, columns=[f\"Vetor{i}\" for i in range(model.vector_size)])\n",
        "    df_word2vec = pd.concat([df, df_vectors], axis=1)\n",
        "    return df_word2vec"
      ],
      "metadata": {
        "id": "1yreuN61JeFH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste de funções"
      ],
      "metadata": {
        "id": "KomhuU9Zgees"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_word2vec(df, 'texto_tratado')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHWLUlP4G3hA",
        "outputId": "d96296eb-756f-4297-d996-c2f428aef714"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_word2vec = create_word2vec_dataframe(df,'texto_tratado', model)\n",
        "df_word2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "qHhtJlUQKDQT",
        "outputId": "47fe1e38-2a25-408b-db69-03484231aae0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         autor  sentimento  \\\n",
              "0                winthegame_of           1   \n",
              "1                   marta_bego           1   \n",
              "2                   lmviapiana           2   \n",
              "3                 vanilson_dos           1   \n",
              "4                  ricktolledo           2   \n",
              "...                        ...         ...   \n",
              "9202  perspectiveinvestimentos           2   \n",
              "9203            eduardocolares           2   \n",
              "9204                 danielucm           2   \n",
              "9205          amgcapitalinvest           1   \n",
              "9206                 bfmarilia           0   \n",
              "\n",
              "                                          texto_tratado  sentimentoNumerico  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...                   1   \n",
              "1     [btgpactual, with, makerepost, entender, impac...                   1   \n",
              "2                                 [minuto, touro, ouro]                   2   \n",
              "3                                                 [sim]                   1   \n",
              "4         [querer, saber, banking, próprio, administro]                   2   \n",
              "...                                                 ...                 ...   \n",
              "9202                            [excelente, explicação]                   2   \n",
              "9203                    [atendar, telefone, amor, deus]                   2   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...                   2   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...                   1   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...                   0   \n",
              "\n",
              "        Vetor0    Vetor1    Vetor2    Vetor3    Vetor4    Vetor5  ...  \\\n",
              "0     0.108135 -0.027515 -0.578618 -0.311223  0.342741  0.582513  ...   \n",
              "1     0.111517  0.001278 -0.552969 -0.288248  0.303032  0.582805  ...   \n",
              "2    -0.055194  0.083907 -0.614759 -0.327277  0.337467  0.614014  ...   \n",
              "3     0.346554  0.100439 -0.466173  0.043146  0.428946  0.523282  ...   \n",
              "4     0.046847 -0.010748 -0.590074 -0.260886  0.367818  0.548250  ...   \n",
              "...        ...       ...       ...       ...       ...       ...  ...   \n",
              "9202  0.206777 -0.020575 -0.546014 -0.393732  0.176287  0.581065  ...   \n",
              "9203  0.144401  0.017314 -0.603351 -0.358521  0.407179  0.616990  ...   \n",
              "9204  0.089300 -0.053939 -0.570320 -0.366888  0.324487  0.588473  ...   \n",
              "9205  0.098567 -0.042418 -0.610832 -0.344497  0.347288  0.611232  ...   \n",
              "9206  0.077178  0.004275 -0.589861 -0.357459  0.381499  0.599922  ...   \n",
              "\n",
              "       Vetor90   Vetor91   Vetor92   Vetor93   Vetor94   Vetor95   Vetor96  \\\n",
              "0    -0.331011  0.171356  0.115854  0.407576 -0.028241 -0.249628 -0.069736   \n",
              "1    -0.310332  0.174199  0.099849  0.379870 -0.034922 -0.238013 -0.091016   \n",
              "2    -0.366691  0.330312  0.197640  0.398107  0.051024 -0.268653  0.009458   \n",
              "3    -0.289289  0.026381  0.406109  0.390878  0.061961 -0.334896 -0.101127   \n",
              "4    -0.355716  0.161371  0.110116  0.369940 -0.011467 -0.228353 -0.078955   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202 -0.263816  0.147015  0.051944  0.460383 -0.122683 -0.294831 -0.124148   \n",
              "9203 -0.403889  0.213475  0.126607  0.399203 -0.023190 -0.247552 -0.013290   \n",
              "9204 -0.287883  0.167735  0.107425  0.404131 -0.069292 -0.231209 -0.054285   \n",
              "9205 -0.323466  0.199106  0.087568  0.430179 -0.046208 -0.250215 -0.102156   \n",
              "9206 -0.396163  0.180069  0.116189  0.392327 -0.041298 -0.225956 -0.010667   \n",
              "\n",
              "       Vetor97   Vetor98   Vetor99  \n",
              "0     0.052952  0.322158 -0.108738  \n",
              "1     0.070340  0.321247 -0.079625  \n",
              "2     0.124287  0.401329 -0.075046  \n",
              "3     0.189571  0.335559 -0.141967  \n",
              "4     0.014221  0.312695 -0.017164  \n",
              "...        ...       ...       ...  \n",
              "9202 -0.062046  0.367368 -0.002227  \n",
              "9203  0.064286  0.328812 -0.115048  \n",
              "9204  0.022797  0.360763 -0.075168  \n",
              "9205  0.031142  0.348474 -0.088865  \n",
              "9206  0.058244  0.296054 -0.078506  \n",
              "\n",
              "[9207 rows x 104 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86b7a6f0-c8c6-4d62-b9b6-e814645560de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>autor</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>texto_tratado</th>\n",
              "      <th>sentimentoNumerico</th>\n",
              "      <th>Vetor0</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor90</th>\n",
              "      <th>Vetor91</th>\n",
              "      <th>Vetor92</th>\n",
              "      <th>Vetor93</th>\n",
              "      <th>Vetor94</th>\n",
              "      <th>Vetor95</th>\n",
              "      <th>Vetor96</th>\n",
              "      <th>Vetor97</th>\n",
              "      <th>Vetor98</th>\n",
              "      <th>Vetor99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>winthegame_of</td>\n",
              "      <td>1</td>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108135</td>\n",
              "      <td>-0.027515</td>\n",
              "      <td>-0.578618</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>0.342741</td>\n",
              "      <td>0.582513</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331011</td>\n",
              "      <td>0.171356</td>\n",
              "      <td>0.115854</td>\n",
              "      <td>0.407576</td>\n",
              "      <td>-0.028241</td>\n",
              "      <td>-0.249628</td>\n",
              "      <td>-0.069736</td>\n",
              "      <td>0.052952</td>\n",
              "      <td>0.322158</td>\n",
              "      <td>-0.108738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marta_bego</td>\n",
              "      <td>1</td>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111517</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>-0.552969</td>\n",
              "      <td>-0.288248</td>\n",
              "      <td>0.303032</td>\n",
              "      <td>0.582805</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310332</td>\n",
              "      <td>0.174199</td>\n",
              "      <td>0.099849</td>\n",
              "      <td>0.379870</td>\n",
              "      <td>-0.034922</td>\n",
              "      <td>-0.238013</td>\n",
              "      <td>-0.091016</td>\n",
              "      <td>0.070340</td>\n",
              "      <td>0.321247</td>\n",
              "      <td>-0.079625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lmviapiana</td>\n",
              "      <td>2</td>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.055194</td>\n",
              "      <td>0.083907</td>\n",
              "      <td>-0.614759</td>\n",
              "      <td>-0.327277</td>\n",
              "      <td>0.337467</td>\n",
              "      <td>0.614014</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.366691</td>\n",
              "      <td>0.330312</td>\n",
              "      <td>0.197640</td>\n",
              "      <td>0.398107</td>\n",
              "      <td>0.051024</td>\n",
              "      <td>-0.268653</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.124287</td>\n",
              "      <td>0.401329</td>\n",
              "      <td>-0.075046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vanilson_dos</td>\n",
              "      <td>1</td>\n",
              "      <td>[sim]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.346554</td>\n",
              "      <td>0.100439</td>\n",
              "      <td>-0.466173</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>0.428946</td>\n",
              "      <td>0.523282</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.289289</td>\n",
              "      <td>0.026381</td>\n",
              "      <td>0.406109</td>\n",
              "      <td>0.390878</td>\n",
              "      <td>0.061961</td>\n",
              "      <td>-0.334896</td>\n",
              "      <td>-0.101127</td>\n",
              "      <td>0.189571</td>\n",
              "      <td>0.335559</td>\n",
              "      <td>-0.141967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ricktolledo</td>\n",
              "      <td>2</td>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.046847</td>\n",
              "      <td>-0.010748</td>\n",
              "      <td>-0.590074</td>\n",
              "      <td>-0.260886</td>\n",
              "      <td>0.367818</td>\n",
              "      <td>0.548250</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355716</td>\n",
              "      <td>0.161371</td>\n",
              "      <td>0.110116</td>\n",
              "      <td>0.369940</td>\n",
              "      <td>-0.011467</td>\n",
              "      <td>-0.228353</td>\n",
              "      <td>-0.078955</td>\n",
              "      <td>0.014221</td>\n",
              "      <td>0.312695</td>\n",
              "      <td>-0.017164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>perspectiveinvestimentos</td>\n",
              "      <td>2</td>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.206777</td>\n",
              "      <td>-0.020575</td>\n",
              "      <td>-0.546014</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>0.176287</td>\n",
              "      <td>0.581065</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263816</td>\n",
              "      <td>0.147015</td>\n",
              "      <td>0.051944</td>\n",
              "      <td>0.460383</td>\n",
              "      <td>-0.122683</td>\n",
              "      <td>-0.294831</td>\n",
              "      <td>-0.124148</td>\n",
              "      <td>-0.062046</td>\n",
              "      <td>0.367368</td>\n",
              "      <td>-0.002227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>eduardocolares</td>\n",
              "      <td>2</td>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.144401</td>\n",
              "      <td>0.017314</td>\n",
              "      <td>-0.603351</td>\n",
              "      <td>-0.358521</td>\n",
              "      <td>0.407179</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403889</td>\n",
              "      <td>0.213475</td>\n",
              "      <td>0.126607</td>\n",
              "      <td>0.399203</td>\n",
              "      <td>-0.023190</td>\n",
              "      <td>-0.247552</td>\n",
              "      <td>-0.013290</td>\n",
              "      <td>0.064286</td>\n",
              "      <td>0.328812</td>\n",
              "      <td>-0.115048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>danielucm</td>\n",
              "      <td>2</td>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.089300</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>-0.570320</td>\n",
              "      <td>-0.366888</td>\n",
              "      <td>0.324487</td>\n",
              "      <td>0.588473</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.287883</td>\n",
              "      <td>0.167735</td>\n",
              "      <td>0.107425</td>\n",
              "      <td>0.404131</td>\n",
              "      <td>-0.069292</td>\n",
              "      <td>-0.231209</td>\n",
              "      <td>-0.054285</td>\n",
              "      <td>0.022797</td>\n",
              "      <td>0.360763</td>\n",
              "      <td>-0.075168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>amgcapitalinvest</td>\n",
              "      <td>1</td>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.098567</td>\n",
              "      <td>-0.042418</td>\n",
              "      <td>-0.610832</td>\n",
              "      <td>-0.344497</td>\n",
              "      <td>0.347288</td>\n",
              "      <td>0.611232</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323466</td>\n",
              "      <td>0.199106</td>\n",
              "      <td>0.087568</td>\n",
              "      <td>0.430179</td>\n",
              "      <td>-0.046208</td>\n",
              "      <td>-0.250215</td>\n",
              "      <td>-0.102156</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.348474</td>\n",
              "      <td>-0.088865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>bfmarilia</td>\n",
              "      <td>0</td>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.077178</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>-0.589861</td>\n",
              "      <td>-0.357459</td>\n",
              "      <td>0.381499</td>\n",
              "      <td>0.599922</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.396163</td>\n",
              "      <td>0.180069</td>\n",
              "      <td>0.116189</td>\n",
              "      <td>0.392327</td>\n",
              "      <td>-0.041298</td>\n",
              "      <td>-0.225956</td>\n",
              "      <td>-0.010667</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.296054</td>\n",
              "      <td>-0.078506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 104 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86b7a6f0-c8c6-4d62-b9b6-e814645560de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86b7a6f0-c8c6-4d62-b9b6-e814645560de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86b7a6f0-c8c6-4d62-b9b6-e814645560de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_word2vec = df_word2vec.drop(columns=['autor', 'sentimento'])\n",
        "df_word2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "_mF6WPhAKb4K",
        "outputId": "bf7a71f1-8569-4992-c883-eb3b851f0328"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          texto_tratado  sentimentoNumerico  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...                   1   \n",
              "1     [btgpactual, with, makerepost, entender, impac...                   1   \n",
              "2                                 [minuto, touro, ouro]                   2   \n",
              "3                                                 [sim]                   1   \n",
              "4         [querer, saber, banking, próprio, administro]                   2   \n",
              "...                                                 ...                 ...   \n",
              "9202                            [excelente, explicação]                   2   \n",
              "9203                    [atendar, telefone, amor, deus]                   2   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...                   2   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...                   1   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...                   0   \n",
              "\n",
              "        Vetor0    Vetor1    Vetor2    Vetor3    Vetor4    Vetor5    Vetor6  \\\n",
              "0     0.108135 -0.027515 -0.578618 -0.311223  0.342741  0.582513 -0.156178   \n",
              "1     0.111517  0.001278 -0.552969 -0.288248  0.303032  0.582805 -0.152977   \n",
              "2    -0.055194  0.083907 -0.614759 -0.327277  0.337467  0.614014 -0.234232   \n",
              "3     0.346554  0.100439 -0.466173  0.043146  0.428946  0.523282 -0.110418   \n",
              "4     0.046847 -0.010748 -0.590074 -0.260886  0.367818  0.548250 -0.176722   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.206777 -0.020575 -0.546014 -0.393732  0.176287  0.581065 -0.148453   \n",
              "9203  0.144401  0.017314 -0.603351 -0.358521  0.407179  0.616990 -0.215791   \n",
              "9204  0.089300 -0.053939 -0.570320 -0.366888  0.324487  0.588473 -0.136371   \n",
              "9205  0.098567 -0.042418 -0.610832 -0.344497  0.347288  0.611232 -0.160629   \n",
              "9206  0.077178  0.004275 -0.589861 -0.357459  0.381499  0.599922 -0.210750   \n",
              "\n",
              "        Vetor7  ...   Vetor90   Vetor91   Vetor92   Vetor93   Vetor94  \\\n",
              "0    -0.078588  ... -0.331011  0.171356  0.115854  0.407576 -0.028241   \n",
              "1    -0.093876  ... -0.310332  0.174199  0.099849  0.379870 -0.034922   \n",
              "2    -0.012530  ... -0.366691  0.330312  0.197640  0.398107  0.051024   \n",
              "3     0.002156  ... -0.289289  0.026381  0.406109  0.390878  0.061961   \n",
              "4    -0.048525  ... -0.355716  0.161371  0.110116  0.369940 -0.011467   \n",
              "...        ...  ...       ...       ...       ...       ...       ...   \n",
              "9202 -0.049564  ... -0.263816  0.147015  0.051944  0.460383 -0.122683   \n",
              "9203 -0.035666  ... -0.403889  0.213475  0.126607  0.399203 -0.023190   \n",
              "9204 -0.078024  ... -0.287883  0.167735  0.107425  0.404131 -0.069292   \n",
              "9205 -0.092984  ... -0.323466  0.199106  0.087568  0.430179 -0.046208   \n",
              "9206 -0.062320  ... -0.396163  0.180069  0.116189  0.392327 -0.041298   \n",
              "\n",
              "       Vetor95   Vetor96   Vetor97   Vetor98   Vetor99  \n",
              "0    -0.249628 -0.069736  0.052952  0.322158 -0.108738  \n",
              "1    -0.238013 -0.091016  0.070340  0.321247 -0.079625  \n",
              "2    -0.268653  0.009458  0.124287  0.401329 -0.075046  \n",
              "3    -0.334896 -0.101127  0.189571  0.335559 -0.141967  \n",
              "4    -0.228353 -0.078955  0.014221  0.312695 -0.017164  \n",
              "...        ...       ...       ...       ...       ...  \n",
              "9202 -0.294831 -0.124148 -0.062046  0.367368 -0.002227  \n",
              "9203 -0.247552 -0.013290  0.064286  0.328812 -0.115048  \n",
              "9204 -0.231209 -0.054285  0.022797  0.360763 -0.075168  \n",
              "9205 -0.250215 -0.102156  0.031142  0.348474 -0.088865  \n",
              "9206 -0.225956 -0.010667  0.058244  0.296054 -0.078506  \n",
              "\n",
              "[9207 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-205b6d2d-5fbe-497d-b1d6-1f5c8453f7dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_tratado</th>\n",
              "      <th>sentimentoNumerico</th>\n",
              "      <th>Vetor0</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor90</th>\n",
              "      <th>Vetor91</th>\n",
              "      <th>Vetor92</th>\n",
              "      <th>Vetor93</th>\n",
              "      <th>Vetor94</th>\n",
              "      <th>Vetor95</th>\n",
              "      <th>Vetor96</th>\n",
              "      <th>Vetor97</th>\n",
              "      <th>Vetor98</th>\n",
              "      <th>Vetor99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108135</td>\n",
              "      <td>-0.027515</td>\n",
              "      <td>-0.578618</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>0.342741</td>\n",
              "      <td>0.582513</td>\n",
              "      <td>-0.156178</td>\n",
              "      <td>-0.078588</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331011</td>\n",
              "      <td>0.171356</td>\n",
              "      <td>0.115854</td>\n",
              "      <td>0.407576</td>\n",
              "      <td>-0.028241</td>\n",
              "      <td>-0.249628</td>\n",
              "      <td>-0.069736</td>\n",
              "      <td>0.052952</td>\n",
              "      <td>0.322158</td>\n",
              "      <td>-0.108738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111517</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>-0.552969</td>\n",
              "      <td>-0.288248</td>\n",
              "      <td>0.303032</td>\n",
              "      <td>0.582805</td>\n",
              "      <td>-0.152977</td>\n",
              "      <td>-0.093876</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310332</td>\n",
              "      <td>0.174199</td>\n",
              "      <td>0.099849</td>\n",
              "      <td>0.379870</td>\n",
              "      <td>-0.034922</td>\n",
              "      <td>-0.238013</td>\n",
              "      <td>-0.091016</td>\n",
              "      <td>0.070340</td>\n",
              "      <td>0.321247</td>\n",
              "      <td>-0.079625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.055194</td>\n",
              "      <td>0.083907</td>\n",
              "      <td>-0.614759</td>\n",
              "      <td>-0.327277</td>\n",
              "      <td>0.337467</td>\n",
              "      <td>0.614014</td>\n",
              "      <td>-0.234232</td>\n",
              "      <td>-0.012530</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.366691</td>\n",
              "      <td>0.330312</td>\n",
              "      <td>0.197640</td>\n",
              "      <td>0.398107</td>\n",
              "      <td>0.051024</td>\n",
              "      <td>-0.268653</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.124287</td>\n",
              "      <td>0.401329</td>\n",
              "      <td>-0.075046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sim]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.346554</td>\n",
              "      <td>0.100439</td>\n",
              "      <td>-0.466173</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>0.428946</td>\n",
              "      <td>0.523282</td>\n",
              "      <td>-0.110418</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.289289</td>\n",
              "      <td>0.026381</td>\n",
              "      <td>0.406109</td>\n",
              "      <td>0.390878</td>\n",
              "      <td>0.061961</td>\n",
              "      <td>-0.334896</td>\n",
              "      <td>-0.101127</td>\n",
              "      <td>0.189571</td>\n",
              "      <td>0.335559</td>\n",
              "      <td>-0.141967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.046847</td>\n",
              "      <td>-0.010748</td>\n",
              "      <td>-0.590074</td>\n",
              "      <td>-0.260886</td>\n",
              "      <td>0.367818</td>\n",
              "      <td>0.548250</td>\n",
              "      <td>-0.176722</td>\n",
              "      <td>-0.048525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355716</td>\n",
              "      <td>0.161371</td>\n",
              "      <td>0.110116</td>\n",
              "      <td>0.369940</td>\n",
              "      <td>-0.011467</td>\n",
              "      <td>-0.228353</td>\n",
              "      <td>-0.078955</td>\n",
              "      <td>0.014221</td>\n",
              "      <td>0.312695</td>\n",
              "      <td>-0.017164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.206777</td>\n",
              "      <td>-0.020575</td>\n",
              "      <td>-0.546014</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>0.176287</td>\n",
              "      <td>0.581065</td>\n",
              "      <td>-0.148453</td>\n",
              "      <td>-0.049564</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263816</td>\n",
              "      <td>0.147015</td>\n",
              "      <td>0.051944</td>\n",
              "      <td>0.460383</td>\n",
              "      <td>-0.122683</td>\n",
              "      <td>-0.294831</td>\n",
              "      <td>-0.124148</td>\n",
              "      <td>-0.062046</td>\n",
              "      <td>0.367368</td>\n",
              "      <td>-0.002227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.144401</td>\n",
              "      <td>0.017314</td>\n",
              "      <td>-0.603351</td>\n",
              "      <td>-0.358521</td>\n",
              "      <td>0.407179</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>-0.215791</td>\n",
              "      <td>-0.035666</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403889</td>\n",
              "      <td>0.213475</td>\n",
              "      <td>0.126607</td>\n",
              "      <td>0.399203</td>\n",
              "      <td>-0.023190</td>\n",
              "      <td>-0.247552</td>\n",
              "      <td>-0.013290</td>\n",
              "      <td>0.064286</td>\n",
              "      <td>0.328812</td>\n",
              "      <td>-0.115048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.089300</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>-0.570320</td>\n",
              "      <td>-0.366888</td>\n",
              "      <td>0.324487</td>\n",
              "      <td>0.588473</td>\n",
              "      <td>-0.136371</td>\n",
              "      <td>-0.078024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.287883</td>\n",
              "      <td>0.167735</td>\n",
              "      <td>0.107425</td>\n",
              "      <td>0.404131</td>\n",
              "      <td>-0.069292</td>\n",
              "      <td>-0.231209</td>\n",
              "      <td>-0.054285</td>\n",
              "      <td>0.022797</td>\n",
              "      <td>0.360763</td>\n",
              "      <td>-0.075168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.098567</td>\n",
              "      <td>-0.042418</td>\n",
              "      <td>-0.610832</td>\n",
              "      <td>-0.344497</td>\n",
              "      <td>0.347288</td>\n",
              "      <td>0.611232</td>\n",
              "      <td>-0.160629</td>\n",
              "      <td>-0.092984</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323466</td>\n",
              "      <td>0.199106</td>\n",
              "      <td>0.087568</td>\n",
              "      <td>0.430179</td>\n",
              "      <td>-0.046208</td>\n",
              "      <td>-0.250215</td>\n",
              "      <td>-0.102156</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.348474</td>\n",
              "      <td>-0.088865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.077178</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>-0.589861</td>\n",
              "      <td>-0.357459</td>\n",
              "      <td>0.381499</td>\n",
              "      <td>0.599922</td>\n",
              "      <td>-0.210750</td>\n",
              "      <td>-0.062320</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.396163</td>\n",
              "      <td>0.180069</td>\n",
              "      <td>0.116189</td>\n",
              "      <td>0.392327</td>\n",
              "      <td>-0.041298</td>\n",
              "      <td>-0.225956</td>\n",
              "      <td>-0.010667</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.296054</td>\n",
              "      <td>-0.078506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 102 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-205b6d2d-5fbe-497d-b1d6-1f5c8453f7dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-205b6d2d-5fbe-497d-b1d6-1f5c8453f7dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-205b6d2d-5fbe-497d-b1d6-1f5c8453f7dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Naive Bayes + Word2Vec com embedding layer"
      ],
      "metadata": {
        "id": "WnFTKfl9aCWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_word2vec = df_word2vec.dropna()\n",
        "df_word2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "outputId": "70a6154a-3113-40d5-ff2e-ed0f16299dc6",
        "id": "Mfi5xF3_aCW2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          texto_tratado  sentimentoNumerico  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...                   1   \n",
              "1     [btgpactual, with, makerepost, entender, impac...                   1   \n",
              "2                                 [minuto, touro, ouro]                   2   \n",
              "3                                                 [sim]                   1   \n",
              "4         [querer, saber, banking, próprio, administro]                   2   \n",
              "...                                                 ...                 ...   \n",
              "9202                            [excelente, explicação]                   2   \n",
              "9203                    [atendar, telefone, amor, deus]                   2   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...                   2   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...                   1   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...                   0   \n",
              "\n",
              "        Vetor0    Vetor1    Vetor2    Vetor3    Vetor4    Vetor5    Vetor6  \\\n",
              "0     0.108135 -0.027515 -0.578618 -0.311223  0.342741  0.582513 -0.156178   \n",
              "1     0.111517  0.001278 -0.552969 -0.288248  0.303032  0.582805 -0.152977   \n",
              "2    -0.055194  0.083907 -0.614759 -0.327277  0.337467  0.614014 -0.234232   \n",
              "3     0.346554  0.100439 -0.466173  0.043146  0.428946  0.523282 -0.110418   \n",
              "4     0.046847 -0.010748 -0.590074 -0.260886  0.367818  0.548250 -0.176722   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.206777 -0.020575 -0.546014 -0.393732  0.176287  0.581065 -0.148453   \n",
              "9203  0.144401  0.017314 -0.603351 -0.358521  0.407179  0.616990 -0.215791   \n",
              "9204  0.089300 -0.053939 -0.570320 -0.366888  0.324487  0.588473 -0.136371   \n",
              "9205  0.098567 -0.042418 -0.610832 -0.344497  0.347288  0.611232 -0.160629   \n",
              "9206  0.077178  0.004275 -0.589861 -0.357459  0.381499  0.599922 -0.210750   \n",
              "\n",
              "        Vetor7  ...   Vetor90   Vetor91   Vetor92   Vetor93   Vetor94  \\\n",
              "0    -0.078588  ... -0.331011  0.171356  0.115854  0.407576 -0.028241   \n",
              "1    -0.093876  ... -0.310332  0.174199  0.099849  0.379870 -0.034922   \n",
              "2    -0.012530  ... -0.366691  0.330312  0.197640  0.398107  0.051024   \n",
              "3     0.002156  ... -0.289289  0.026381  0.406109  0.390878  0.061961   \n",
              "4    -0.048525  ... -0.355716  0.161371  0.110116  0.369940 -0.011467   \n",
              "...        ...  ...       ...       ...       ...       ...       ...   \n",
              "9202 -0.049564  ... -0.263816  0.147015  0.051944  0.460383 -0.122683   \n",
              "9203 -0.035666  ... -0.403889  0.213475  0.126607  0.399203 -0.023190   \n",
              "9204 -0.078024  ... -0.287883  0.167735  0.107425  0.404131 -0.069292   \n",
              "9205 -0.092984  ... -0.323466  0.199106  0.087568  0.430179 -0.046208   \n",
              "9206 -0.062320  ... -0.396163  0.180069  0.116189  0.392327 -0.041298   \n",
              "\n",
              "       Vetor95   Vetor96   Vetor97   Vetor98   Vetor99  \n",
              "0    -0.249628 -0.069736  0.052952  0.322158 -0.108738  \n",
              "1    -0.238013 -0.091016  0.070340  0.321247 -0.079625  \n",
              "2    -0.268653  0.009458  0.124287  0.401329 -0.075046  \n",
              "3    -0.334896 -0.101127  0.189571  0.335559 -0.141967  \n",
              "4    -0.228353 -0.078955  0.014221  0.312695 -0.017164  \n",
              "...        ...       ...       ...       ...       ...  \n",
              "9202 -0.294831 -0.124148 -0.062046  0.367368 -0.002227  \n",
              "9203 -0.247552 -0.013290  0.064286  0.328812 -0.115048  \n",
              "9204 -0.231209 -0.054285  0.022797  0.360763 -0.075168  \n",
              "9205 -0.250215 -0.102156  0.031142  0.348474 -0.088865  \n",
              "9206 -0.225956 -0.010667  0.058244  0.296054 -0.078506  \n",
              "\n",
              "[9207 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64361fbe-6ce9-4c88-aed5-9e59000ef867\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_tratado</th>\n",
              "      <th>sentimentoNumerico</th>\n",
              "      <th>Vetor0</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor90</th>\n",
              "      <th>Vetor91</th>\n",
              "      <th>Vetor92</th>\n",
              "      <th>Vetor93</th>\n",
              "      <th>Vetor94</th>\n",
              "      <th>Vetor95</th>\n",
              "      <th>Vetor96</th>\n",
              "      <th>Vetor97</th>\n",
              "      <th>Vetor98</th>\n",
              "      <th>Vetor99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108135</td>\n",
              "      <td>-0.027515</td>\n",
              "      <td>-0.578618</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>0.342741</td>\n",
              "      <td>0.582513</td>\n",
              "      <td>-0.156178</td>\n",
              "      <td>-0.078588</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331011</td>\n",
              "      <td>0.171356</td>\n",
              "      <td>0.115854</td>\n",
              "      <td>0.407576</td>\n",
              "      <td>-0.028241</td>\n",
              "      <td>-0.249628</td>\n",
              "      <td>-0.069736</td>\n",
              "      <td>0.052952</td>\n",
              "      <td>0.322158</td>\n",
              "      <td>-0.108738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111517</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>-0.552969</td>\n",
              "      <td>-0.288248</td>\n",
              "      <td>0.303032</td>\n",
              "      <td>0.582805</td>\n",
              "      <td>-0.152977</td>\n",
              "      <td>-0.093876</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310332</td>\n",
              "      <td>0.174199</td>\n",
              "      <td>0.099849</td>\n",
              "      <td>0.379870</td>\n",
              "      <td>-0.034922</td>\n",
              "      <td>-0.238013</td>\n",
              "      <td>-0.091016</td>\n",
              "      <td>0.070340</td>\n",
              "      <td>0.321247</td>\n",
              "      <td>-0.079625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.055194</td>\n",
              "      <td>0.083907</td>\n",
              "      <td>-0.614759</td>\n",
              "      <td>-0.327277</td>\n",
              "      <td>0.337467</td>\n",
              "      <td>0.614014</td>\n",
              "      <td>-0.234232</td>\n",
              "      <td>-0.012530</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.366691</td>\n",
              "      <td>0.330312</td>\n",
              "      <td>0.197640</td>\n",
              "      <td>0.398107</td>\n",
              "      <td>0.051024</td>\n",
              "      <td>-0.268653</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.124287</td>\n",
              "      <td>0.401329</td>\n",
              "      <td>-0.075046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sim]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.346554</td>\n",
              "      <td>0.100439</td>\n",
              "      <td>-0.466173</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>0.428946</td>\n",
              "      <td>0.523282</td>\n",
              "      <td>-0.110418</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.289289</td>\n",
              "      <td>0.026381</td>\n",
              "      <td>0.406109</td>\n",
              "      <td>0.390878</td>\n",
              "      <td>0.061961</td>\n",
              "      <td>-0.334896</td>\n",
              "      <td>-0.101127</td>\n",
              "      <td>0.189571</td>\n",
              "      <td>0.335559</td>\n",
              "      <td>-0.141967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.046847</td>\n",
              "      <td>-0.010748</td>\n",
              "      <td>-0.590074</td>\n",
              "      <td>-0.260886</td>\n",
              "      <td>0.367818</td>\n",
              "      <td>0.548250</td>\n",
              "      <td>-0.176722</td>\n",
              "      <td>-0.048525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355716</td>\n",
              "      <td>0.161371</td>\n",
              "      <td>0.110116</td>\n",
              "      <td>0.369940</td>\n",
              "      <td>-0.011467</td>\n",
              "      <td>-0.228353</td>\n",
              "      <td>-0.078955</td>\n",
              "      <td>0.014221</td>\n",
              "      <td>0.312695</td>\n",
              "      <td>-0.017164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.206777</td>\n",
              "      <td>-0.020575</td>\n",
              "      <td>-0.546014</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>0.176287</td>\n",
              "      <td>0.581065</td>\n",
              "      <td>-0.148453</td>\n",
              "      <td>-0.049564</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263816</td>\n",
              "      <td>0.147015</td>\n",
              "      <td>0.051944</td>\n",
              "      <td>0.460383</td>\n",
              "      <td>-0.122683</td>\n",
              "      <td>-0.294831</td>\n",
              "      <td>-0.124148</td>\n",
              "      <td>-0.062046</td>\n",
              "      <td>0.367368</td>\n",
              "      <td>-0.002227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.144401</td>\n",
              "      <td>0.017314</td>\n",
              "      <td>-0.603351</td>\n",
              "      <td>-0.358521</td>\n",
              "      <td>0.407179</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>-0.215791</td>\n",
              "      <td>-0.035666</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403889</td>\n",
              "      <td>0.213475</td>\n",
              "      <td>0.126607</td>\n",
              "      <td>0.399203</td>\n",
              "      <td>-0.023190</td>\n",
              "      <td>-0.247552</td>\n",
              "      <td>-0.013290</td>\n",
              "      <td>0.064286</td>\n",
              "      <td>0.328812</td>\n",
              "      <td>-0.115048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.089300</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>-0.570320</td>\n",
              "      <td>-0.366888</td>\n",
              "      <td>0.324487</td>\n",
              "      <td>0.588473</td>\n",
              "      <td>-0.136371</td>\n",
              "      <td>-0.078024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.287883</td>\n",
              "      <td>0.167735</td>\n",
              "      <td>0.107425</td>\n",
              "      <td>0.404131</td>\n",
              "      <td>-0.069292</td>\n",
              "      <td>-0.231209</td>\n",
              "      <td>-0.054285</td>\n",
              "      <td>0.022797</td>\n",
              "      <td>0.360763</td>\n",
              "      <td>-0.075168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.098567</td>\n",
              "      <td>-0.042418</td>\n",
              "      <td>-0.610832</td>\n",
              "      <td>-0.344497</td>\n",
              "      <td>0.347288</td>\n",
              "      <td>0.611232</td>\n",
              "      <td>-0.160629</td>\n",
              "      <td>-0.092984</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323466</td>\n",
              "      <td>0.199106</td>\n",
              "      <td>0.087568</td>\n",
              "      <td>0.430179</td>\n",
              "      <td>-0.046208</td>\n",
              "      <td>-0.250215</td>\n",
              "      <td>-0.102156</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.348474</td>\n",
              "      <td>-0.088865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.077178</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>-0.589861</td>\n",
              "      <td>-0.357459</td>\n",
              "      <td>0.381499</td>\n",
              "      <td>0.599922</td>\n",
              "      <td>-0.210750</td>\n",
              "      <td>-0.062320</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.396163</td>\n",
              "      <td>0.180069</td>\n",
              "      <td>0.116189</td>\n",
              "      <td>0.392327</td>\n",
              "      <td>-0.041298</td>\n",
              "      <td>-0.225956</td>\n",
              "      <td>-0.010667</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.296054</td>\n",
              "      <td>-0.078506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 102 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64361fbe-6ce9-4c88-aed5-9e59000ef867')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64361fbe-6ce9-4c88-aed5-9e59000ef867 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64361fbe-6ce9-4c88-aed5-9e59000ef867');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separando Treino e Teste"
      ],
      "metadata": {
        "id": "avPYp8x4aCW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = df_word2vec['sentimentoNumerico']"
      ],
      "metadata": {
        "id": "EaUZ4Pl0aCW3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = df_word2vec.iloc[:,2:102]"
      ],
      "metadata": {
        "id": "j5nWA5fKaCW4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "64b0dfe5-983e-4c4e-f304-e70e19308132",
        "id": "Fi46W-u1aCW4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Vetor0    Vetor1    Vetor2    Vetor3    Vetor4    Vetor5    Vetor6  \\\n",
              "0     0.108135 -0.027515 -0.578618 -0.311223  0.342741  0.582513 -0.156178   \n",
              "1     0.111517  0.001278 -0.552969 -0.288248  0.303032  0.582805 -0.152977   \n",
              "2    -0.055194  0.083907 -0.614759 -0.327277  0.337467  0.614014 -0.234232   \n",
              "3     0.346554  0.100439 -0.466173  0.043146  0.428946  0.523282 -0.110418   \n",
              "4     0.046847 -0.010748 -0.590074 -0.260886  0.367818  0.548250 -0.176722   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.206777 -0.020575 -0.546014 -0.393732  0.176287  0.581065 -0.148453   \n",
              "9203  0.144401  0.017314 -0.603351 -0.358521  0.407179  0.616990 -0.215791   \n",
              "9204  0.089300 -0.053939 -0.570320 -0.366888  0.324487  0.588473 -0.136371   \n",
              "9205  0.098567 -0.042418 -0.610832 -0.344497  0.347288  0.611232 -0.160629   \n",
              "9206  0.077178  0.004275 -0.589861 -0.357459  0.381499  0.599922 -0.210750   \n",
              "\n",
              "        Vetor7    Vetor8    Vetor9  ...   Vetor90   Vetor91   Vetor92  \\\n",
              "0    -0.078588  0.180663  0.259550  ... -0.331011  0.171356  0.115854   \n",
              "1    -0.093876  0.157012  0.274025  ... -0.310332  0.174199  0.099849   \n",
              "2    -0.012530  0.102668  0.380476  ... -0.366691  0.330312  0.197640   \n",
              "3     0.002156 -0.029682  0.382829  ... -0.289289  0.026381  0.406109   \n",
              "4    -0.048525  0.113752  0.267164  ... -0.355716  0.161371  0.110116   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9202 -0.049564  0.085221  0.200708  ... -0.263816  0.147015  0.051944   \n",
              "9203 -0.035666  0.215714  0.244427  ... -0.403889  0.213475  0.126607   \n",
              "9204 -0.078024  0.156528  0.250180  ... -0.287883  0.167735  0.107425   \n",
              "9205 -0.092984  0.173459  0.264204  ... -0.323466  0.199106  0.087568   \n",
              "9206 -0.062320  0.183476  0.280060  ... -0.396163  0.180069  0.116189   \n",
              "\n",
              "       Vetor93   Vetor94   Vetor95   Vetor96   Vetor97   Vetor98   Vetor99  \n",
              "0     0.407576 -0.028241 -0.249628 -0.069736  0.052952  0.322158 -0.108738  \n",
              "1     0.379870 -0.034922 -0.238013 -0.091016  0.070340  0.321247 -0.079625  \n",
              "2     0.398107  0.051024 -0.268653  0.009458  0.124287  0.401329 -0.075046  \n",
              "3     0.390878  0.061961 -0.334896 -0.101127  0.189571  0.335559 -0.141967  \n",
              "4     0.369940 -0.011467 -0.228353 -0.078955  0.014221  0.312695 -0.017164  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "9202  0.460383 -0.122683 -0.294831 -0.124148 -0.062046  0.367368 -0.002227  \n",
              "9203  0.399203 -0.023190 -0.247552 -0.013290  0.064286  0.328812 -0.115048  \n",
              "9204  0.404131 -0.069292 -0.231209 -0.054285  0.022797  0.360763 -0.075168  \n",
              "9205  0.430179 -0.046208 -0.250215 -0.102156  0.031142  0.348474 -0.088865  \n",
              "9206  0.392327 -0.041298 -0.225956 -0.010667  0.058244  0.296054 -0.078506  \n",
              "\n",
              "[9207 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba53d5f7-a274-4d8a-b5f3-909609629f97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vetor0</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>Vetor8</th>\n",
              "      <th>Vetor9</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor90</th>\n",
              "      <th>Vetor91</th>\n",
              "      <th>Vetor92</th>\n",
              "      <th>Vetor93</th>\n",
              "      <th>Vetor94</th>\n",
              "      <th>Vetor95</th>\n",
              "      <th>Vetor96</th>\n",
              "      <th>Vetor97</th>\n",
              "      <th>Vetor98</th>\n",
              "      <th>Vetor99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.108135</td>\n",
              "      <td>-0.027515</td>\n",
              "      <td>-0.578618</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>0.342741</td>\n",
              "      <td>0.582513</td>\n",
              "      <td>-0.156178</td>\n",
              "      <td>-0.078588</td>\n",
              "      <td>0.180663</td>\n",
              "      <td>0.259550</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331011</td>\n",
              "      <td>0.171356</td>\n",
              "      <td>0.115854</td>\n",
              "      <td>0.407576</td>\n",
              "      <td>-0.028241</td>\n",
              "      <td>-0.249628</td>\n",
              "      <td>-0.069736</td>\n",
              "      <td>0.052952</td>\n",
              "      <td>0.322158</td>\n",
              "      <td>-0.108738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.111517</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>-0.552969</td>\n",
              "      <td>-0.288248</td>\n",
              "      <td>0.303032</td>\n",
              "      <td>0.582805</td>\n",
              "      <td>-0.152977</td>\n",
              "      <td>-0.093876</td>\n",
              "      <td>0.157012</td>\n",
              "      <td>0.274025</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310332</td>\n",
              "      <td>0.174199</td>\n",
              "      <td>0.099849</td>\n",
              "      <td>0.379870</td>\n",
              "      <td>-0.034922</td>\n",
              "      <td>-0.238013</td>\n",
              "      <td>-0.091016</td>\n",
              "      <td>0.070340</td>\n",
              "      <td>0.321247</td>\n",
              "      <td>-0.079625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.055194</td>\n",
              "      <td>0.083907</td>\n",
              "      <td>-0.614759</td>\n",
              "      <td>-0.327277</td>\n",
              "      <td>0.337467</td>\n",
              "      <td>0.614014</td>\n",
              "      <td>-0.234232</td>\n",
              "      <td>-0.012530</td>\n",
              "      <td>0.102668</td>\n",
              "      <td>0.380476</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.366691</td>\n",
              "      <td>0.330312</td>\n",
              "      <td>0.197640</td>\n",
              "      <td>0.398107</td>\n",
              "      <td>0.051024</td>\n",
              "      <td>-0.268653</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.124287</td>\n",
              "      <td>0.401329</td>\n",
              "      <td>-0.075046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.346554</td>\n",
              "      <td>0.100439</td>\n",
              "      <td>-0.466173</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>0.428946</td>\n",
              "      <td>0.523282</td>\n",
              "      <td>-0.110418</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>-0.029682</td>\n",
              "      <td>0.382829</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.289289</td>\n",
              "      <td>0.026381</td>\n",
              "      <td>0.406109</td>\n",
              "      <td>0.390878</td>\n",
              "      <td>0.061961</td>\n",
              "      <td>-0.334896</td>\n",
              "      <td>-0.101127</td>\n",
              "      <td>0.189571</td>\n",
              "      <td>0.335559</td>\n",
              "      <td>-0.141967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.046847</td>\n",
              "      <td>-0.010748</td>\n",
              "      <td>-0.590074</td>\n",
              "      <td>-0.260886</td>\n",
              "      <td>0.367818</td>\n",
              "      <td>0.548250</td>\n",
              "      <td>-0.176722</td>\n",
              "      <td>-0.048525</td>\n",
              "      <td>0.113752</td>\n",
              "      <td>0.267164</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355716</td>\n",
              "      <td>0.161371</td>\n",
              "      <td>0.110116</td>\n",
              "      <td>0.369940</td>\n",
              "      <td>-0.011467</td>\n",
              "      <td>-0.228353</td>\n",
              "      <td>-0.078955</td>\n",
              "      <td>0.014221</td>\n",
              "      <td>0.312695</td>\n",
              "      <td>-0.017164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>0.206777</td>\n",
              "      <td>-0.020575</td>\n",
              "      <td>-0.546014</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>0.176287</td>\n",
              "      <td>0.581065</td>\n",
              "      <td>-0.148453</td>\n",
              "      <td>-0.049564</td>\n",
              "      <td>0.085221</td>\n",
              "      <td>0.200708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263816</td>\n",
              "      <td>0.147015</td>\n",
              "      <td>0.051944</td>\n",
              "      <td>0.460383</td>\n",
              "      <td>-0.122683</td>\n",
              "      <td>-0.294831</td>\n",
              "      <td>-0.124148</td>\n",
              "      <td>-0.062046</td>\n",
              "      <td>0.367368</td>\n",
              "      <td>-0.002227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>0.144401</td>\n",
              "      <td>0.017314</td>\n",
              "      <td>-0.603351</td>\n",
              "      <td>-0.358521</td>\n",
              "      <td>0.407179</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>-0.215791</td>\n",
              "      <td>-0.035666</td>\n",
              "      <td>0.215714</td>\n",
              "      <td>0.244427</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403889</td>\n",
              "      <td>0.213475</td>\n",
              "      <td>0.126607</td>\n",
              "      <td>0.399203</td>\n",
              "      <td>-0.023190</td>\n",
              "      <td>-0.247552</td>\n",
              "      <td>-0.013290</td>\n",
              "      <td>0.064286</td>\n",
              "      <td>0.328812</td>\n",
              "      <td>-0.115048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>0.089300</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>-0.570320</td>\n",
              "      <td>-0.366888</td>\n",
              "      <td>0.324487</td>\n",
              "      <td>0.588473</td>\n",
              "      <td>-0.136371</td>\n",
              "      <td>-0.078024</td>\n",
              "      <td>0.156528</td>\n",
              "      <td>0.250180</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.287883</td>\n",
              "      <td>0.167735</td>\n",
              "      <td>0.107425</td>\n",
              "      <td>0.404131</td>\n",
              "      <td>-0.069292</td>\n",
              "      <td>-0.231209</td>\n",
              "      <td>-0.054285</td>\n",
              "      <td>0.022797</td>\n",
              "      <td>0.360763</td>\n",
              "      <td>-0.075168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>0.098567</td>\n",
              "      <td>-0.042418</td>\n",
              "      <td>-0.610832</td>\n",
              "      <td>-0.344497</td>\n",
              "      <td>0.347288</td>\n",
              "      <td>0.611232</td>\n",
              "      <td>-0.160629</td>\n",
              "      <td>-0.092984</td>\n",
              "      <td>0.173459</td>\n",
              "      <td>0.264204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323466</td>\n",
              "      <td>0.199106</td>\n",
              "      <td>0.087568</td>\n",
              "      <td>0.430179</td>\n",
              "      <td>-0.046208</td>\n",
              "      <td>-0.250215</td>\n",
              "      <td>-0.102156</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.348474</td>\n",
              "      <td>-0.088865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>0.077178</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>-0.589861</td>\n",
              "      <td>-0.357459</td>\n",
              "      <td>0.381499</td>\n",
              "      <td>0.599922</td>\n",
              "      <td>-0.210750</td>\n",
              "      <td>-0.062320</td>\n",
              "      <td>0.183476</td>\n",
              "      <td>0.280060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.396163</td>\n",
              "      <td>0.180069</td>\n",
              "      <td>0.116189</td>\n",
              "      <td>0.392327</td>\n",
              "      <td>-0.041298</td>\n",
              "      <td>-0.225956</td>\n",
              "      <td>-0.010667</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.296054</td>\n",
              "      <td>-0.078506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba53d5f7-a274-4d8a-b5f3-909609629f97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba53d5f7-a274-4d8a-b5f3-909609629f97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba53d5f7-a274-4d8a-b5f3-909609629f97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fnFgD3GEaCW5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do modelo "
      ],
      "metadata": {
        "id": "DBdVTALIaCW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GaussianNB()\n",
        "\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83bef08b-0d3a-4474-8561-451909fb2cce",
        "id": "njvM5MUFaCW6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.83      0.42       386\n",
            "           1       0.78      0.46      0.57       844\n",
            "           2       0.35      0.11      0.17       612\n",
            "\n",
            "    accuracy                           0.42      1842\n",
            "   macro avg       0.47      0.47      0.39      1842\n",
            "weighted avg       0.53      0.42      0.41      1842\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_score = accuracy_score(y_test, Y_pred)\n",
        "format_output = \"{:.2%}\".format(acc_score)\n",
        "print(\"Precisão final de :\",format_output) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5127892b-1a18-43b7-d556-cfc8cbfc8ba4",
        "id": "oDgwNC3baCW6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão final de : 42.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rede Neural - Sequência de palavras"
      ],
      "metadata": {
        "id": "4OviorCPSvc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste isolado"
      ],
      "metadata": {
        "id": "C-gVmNNSi4GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pad_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5C0QuOaT-lc",
        "outputId": "88fbc8c0-7494-4a6c-a0b4-e016752a1c2c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pad_sequences\n",
            "  Downloading pad-sequences-0.6.1.tar.gz (9.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pad_sequences\n",
            "  Building wheel for pad_sequences (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pad_sequences: filename=pad_sequences-0.6.1-py3-none-any.whl size=10199 sha256=0c842d09650de040385575046712761506253e3047ce8161751a698bc2b638e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/9d/22/0a6305b87a9cc46ccc032060a041c3b59f39ac462f7358997e\n",
            "Successfully built pad_sequences\n",
            "Installing collected packages: pad_sequences\n",
            "Successfully installed pad_sequences-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "#from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "citacao = [\n",
        "    \"Estudo no Inteli e escolhi o curso de Sistemas de Informação\",\n",
        "    \"Estamos fazendo um projeto para o BTG\",\n",
        "    \"Estamos no segundo ano de graduação\",\n",
        "    \"Somos do grupo BTG3\"\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(citacao)\n",
        "citacao_token = tokenizer.texts_to_sequences(citacao)\n",
        "\n",
        "max_length = max([len(z) for z in citacao_token]) + 1\n",
        "citacao_pad = pad_sequences(citacao_token, maxlen=max_length, padding=\"post\")"
      ],
      "metadata": {
        "id": "Y_xreGabTpG1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção da rede neural + resultados - base tratada"
      ],
      "metadata": {
        "id": "Y2aZCiZ-XnZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A rede neural abaixo foi desenvolvida com o tutorial mencionado no ínicio do notebook, que, nesse caso o dataframe utilizado é um arquivo com a base que já passou pelo pré processamento. "
      ],
      "metadata": {
        "id": "Iuk3ublePShC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset já treinado"
      ],
      "metadata": {
        "id": "wBhZnhe-JFrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rede_neural_df = pd.read_csv(\"/content/drive/MyDrive/Módulo 6/Sprint 3 - Projeto/nova_base_tratada (1)\")"
      ],
      "metadata": {
        "id": "P-CHvEecd5h-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_neural_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cHHrloH2d6VQ",
        "outputId": "fe85060a-739b-4e81-d41b-b0b038d63c90"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                     autor  sentimento  \\\n",
              "0              0             winthegame_of           1   \n",
              "1              1                marta_bego           1   \n",
              "2              2                lmviapiana           2   \n",
              "3              3              vanilson_dos           1   \n",
              "4              4               ricktolledo           2   \n",
              "...          ...                       ...         ...   \n",
              "9202        9472  perspectiveinvestimentos           2   \n",
              "9203        9473            eduardocolares           2   \n",
              "9204        9474                 danielucm           2   \n",
              "9205        9475          amgcapitalinvest           1   \n",
              "9206        9476                 bfmarilia           0   \n",
              "\n",
              "                                          texto_tratado  \n",
              "0     ['alvarez', 'marsal', 'estar', 'conosco', 'spo...  \n",
              "1     ['btgpactual', 'with', 'makerepost', 'entender...  \n",
              "2                           ['minuto', 'touro', 'ouro']  \n",
              "3                                               ['sim']  \n",
              "4     ['querer', 'saber', 'banking', 'próprio', 'adm...  \n",
              "...                                                 ...  \n",
              "9202                        ['excelente', 'explicação']  \n",
              "9203            ['atendar', 'telefone', 'amor', 'deus']  \n",
              "9204  ['saber', 'qual', 'grande', 'fiis', 'mercado',...  \n",
              "9205  ['erro', 'financeiro', 'eliminar', 'antes', 'a...  \n",
              "9206  ['porque', 'morning', 'call', 'aparecer', 'spo...  \n",
              "\n",
              "[9207 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-480599bd-ac92-49ad-b8eb-98b0d6188531\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>autor</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>texto_tratado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>winthegame_of</td>\n",
              "      <td>1</td>\n",
              "      <td>['alvarez', 'marsal', 'estar', 'conosco', 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>marta_bego</td>\n",
              "      <td>1</td>\n",
              "      <td>['btgpactual', 'with', 'makerepost', 'entender...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lmviapiana</td>\n",
              "      <td>2</td>\n",
              "      <td>['minuto', 'touro', 'ouro']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>vanilson_dos</td>\n",
              "      <td>1</td>\n",
              "      <td>['sim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ricktolledo</td>\n",
              "      <td>2</td>\n",
              "      <td>['querer', 'saber', 'banking', 'próprio', 'adm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>9472</td>\n",
              "      <td>perspectiveinvestimentos</td>\n",
              "      <td>2</td>\n",
              "      <td>['excelente', 'explicação']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>9473</td>\n",
              "      <td>eduardocolares</td>\n",
              "      <td>2</td>\n",
              "      <td>['atendar', 'telefone', 'amor', 'deus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>9474</td>\n",
              "      <td>danielucm</td>\n",
              "      <td>2</td>\n",
              "      <td>['saber', 'qual', 'grande', 'fiis', 'mercado',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>9475</td>\n",
              "      <td>amgcapitalinvest</td>\n",
              "      <td>1</td>\n",
              "      <td>['erro', 'financeiro', 'eliminar', 'antes', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>9476</td>\n",
              "      <td>bfmarilia</td>\n",
              "      <td>0</td>\n",
              "      <td>['porque', 'morning', 'call', 'aparecer', 'spo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-480599bd-ac92-49ad-b8eb-98b0d6188531')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-480599bd-ac92-49ad-b8eb-98b0d6188531 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-480599bd-ac92-49ad-b8eb-98b0d6188531');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação de treino e teste"
      ],
      "metadata": {
        "id": "4ygW6q6LMrPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = rede_neural_df[\"texto_tratado\"], rede_neural_df[\"sentimento\"]\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "words = [\"o\", \"ao\", 'aos', 'os', 'a', 'as', 'e', 'um', 'uma', \n",
        "        'ele', 'ela', 'eles', 'elas', 'do', 'da', 'dos', 'das', \n",
        "        'de', 'no', 'na', 'nos', 'nas', 'pelo', 'pela', 'pelos', \n",
        "        'pelas', 'num', 'numa', 'nuns', 'numas', 'dum', 'duma', \n",
        "        'duns', 'dumas']\n",
        "\n",
        "x_filter = []\n",
        "\n",
        "for title in x:\n",
        "  for word in words:\n",
        "    title = title.replace(word, '')\n",
        "  x_filter.append(title)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_filter)\n",
        "\n",
        "vocab = len(tokenizer.word_docs) + 1\n",
        "\n",
        "x_filter = tokenizer.texts_to_sequences(x_filter)\n",
        "\n",
        "max_length = max([len(z) for z in x_filter])\n",
        "x_filter = pad_sequences(x_filter, maxlen=max_length, padding='post')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_filter, y, test_size=0.33)\n",
        "\n",
        "print(\"Tamanho de x:\", len(x_filter))\n",
        "print(\"Tamanho de y:\", len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TsSixbaYOsv",
        "outputId": "c134601b-ec20-4ea6-f550-d6bf19363233"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de x: 9207\n",
            "Tamanho de y: 9207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criação do modelo"
      ],
      "metadata": {
        "id": "RemTHDtxMxAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "model_rede_neural_df = Sequential()\n",
        "model_rede_neural_df.add(Embedding(input_dim=vocab, output_dim=80, input_length=max_length, trainable=True))\n",
        "model_rede_neural_df.add(GlobalMaxPooling1D())\n",
        "model_rede_neural_df.add(Dropout(0.3))\n",
        "model_rede_neural_df.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model_rede_neural_df.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[recall])\n",
        "\n",
        "mc = ModelCheckpoint('weight.best.hdf5', monitor='val_acc', save_best_only=True, mode='max')\n",
        "\n",
        "model_rede_neural_df.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=10, callbacks=[mc])\n",
        "\n",
        "print(model_rede_neural_df.evaluate(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsSN2KJugfTH",
        "outputId": "d3146813-7d1e-4082-9b15-8f7440dccad4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "191/193 [============================>.] - ETA: 0s - loss: 1.0023 - recall: 1.2226"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 6s 26ms/step - loss: 1.0021 - recall: 1.2221 - val_loss: 0.9181 - val_recall: 1.1206\n",
            "Epoch 2/10\n",
            "191/193 [============================>.] - ETA: 0s - loss: 0.8262 - recall: 1.1923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 7s 35ms/step - loss: 0.8252 - recall: 1.1934 - val_loss: 0.7949 - val_recall: 1.1414\n",
            "Epoch 3/10\n",
            "191/193 [============================>.] - ETA: 0s - loss: 0.6936 - recall: 1.2018"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 21ms/step - loss: 0.6951 - recall: 1.2025 - val_loss: 0.7240 - val_recall: 1.1495\n",
            "Epoch 4/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.5918 - recall: 1.1897"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 24ms/step - loss: 0.5918 - recall: 1.1897 - val_loss: 0.6815 - val_recall: 1.1324\n",
            "Epoch 5/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.5073 - recall: 1.1535"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 27ms/step - loss: 0.5072 - recall: 1.1530 - val_loss: 0.6581 - val_recall: 1.1011\n",
            "Epoch 6/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.4384 - recall: 1.1206"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 6s 30ms/step - loss: 0.4384 - recall: 1.1206 - val_loss: 0.6427 - val_recall: 1.1096\n",
            "Epoch 7/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.3780 - recall: 1.1048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 7s 35ms/step - loss: 0.3781 - recall: 1.1037 - val_loss: 0.6386 - val_recall: 1.0971\n",
            "Epoch 8/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.3305 - recall: 1.0856"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 6s 33ms/step - loss: 0.3302 - recall: 1.0858 - val_loss: 0.6344 - val_recall: 1.1005\n",
            "Epoch 9/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.2935 - recall: 1.0814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 21ms/step - loss: 0.2931 - recall: 1.0812 - val_loss: 0.6362 - val_recall: 1.0920\n",
            "Epoch 10/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.2566 - recall: 1.0621"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193/193 [==============================] - 5s 27ms/step - loss: 0.2566 - recall: 1.0621 - val_loss: 0.6403 - val_recall: 1.0947\n",
            "95/95 [==============================] - 0s 4ms/step - loss: 0.6403 - recall: 1.0947\n",
            "[0.6402556896209717, 1.0946693420410156]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relatório de Classificação e matiz de confusão"
      ],
      "metadata": {
        "id": "lhvhN4WH8zfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model_rede_neural_df.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1) \n",
        "\n",
        "classification = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnDNoh3jjEEN",
        "outputId": "7e6df721-990c-4533-f94f-cc8ce96981be"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95/95 [==============================] - 0s 4ms/step\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.68      0.69       662\n",
            "           1       0.77      0.76      0.77      1358\n",
            "           2       0.71      0.73      0.72      1019\n",
            "\n",
            "    accuracy                           0.73      3039\n",
            "   macro avg       0.72      0.72      0.72      3039\n",
            "weighted avg       0.73      0.73      0.73      3039\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "classes = ['Classe 1', 'Classe 2', 'Classe 3']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot\n",
        "=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "yRPrZliJd4K6",
        "outputId": "7fa4ec75-f95a-4484-bab1-b9ea92aeef42"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportação com a biblioteca pickle"
      ],
      "metadata": {
        "id": "g8MEcsUDMzoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('redeNeural_base_sprint3.pkl', 'wb') as arquivo:\n",
        "    pickle.dump(model_rede_neural_df, arquivo)\n",
        "with open('redeNeural_base_sprint3.pkl', 'rb') as arquivo:\n",
        "    modelo_redeNeural_base_sprint3 = pickle.load(arquivo)"
      ],
      "metadata": {
        "id": "hTj_RkeD_PHl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção da rede neural + resultados - word2vec com cbow"
      ],
      "metadata": {
        "id": "rSKnj9VgjFPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A rede neural abaixo foi desenvolvida com o tutorial mencionado no ínicio do notebook, que, nesse caso o dataframe utilizado é a variável do Word2Vec com o CBoW. "
      ],
      "metadata": {
        "id": "AZjcD9FgPlSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe do word2vec com o cbow\n"
      ],
      "metadata": {
        "id": "bf7YfkMEM9qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "aNuxvCE8jLcA",
        "outputId": "42fa0b98-dc62-42ed-a433-cf6886d43b51"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Frase    Vetor1    Vetor2  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...  0.213634 -0.129877   \n",
              "1     [btgpactual, with, makerepost, entender, impac...  0.222697 -0.124886   \n",
              "2                                 [minuto, touro, ouro]  0.265227 -0.068285   \n",
              "3                                                 [sim]  0.166258 -0.029796   \n",
              "4         [querer, saber, banking, próprio, administro]  0.187512 -0.183612   \n",
              "...                                                 ...       ...       ...   \n",
              "9202                            [excelente, explicação]  0.190917 -0.133475   \n",
              "9203                    [atendar, telefone, amor, deus]  0.188641 -0.119377   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...  0.215474 -0.137852   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...  0.219393 -0.129317   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...  0.225402 -0.137580   \n",
              "\n",
              "        Vetor3    Vetor4    Vetor5    Vetor6    Vetor7    Vetor8    Vetor9  \\\n",
              "0     0.241601 -0.075002 -0.015629  0.206194  0.072658  0.055472  0.061554   \n",
              "1     0.213157 -0.059091 -0.010530  0.201566  0.071898  0.033920  0.059524   \n",
              "2     0.152235 -0.044329 -0.102729  0.141353  0.092800  0.113174  0.015783   \n",
              "3     0.204045 -0.297490  0.046077  0.140763  0.035251 -0.174491  0.211817   \n",
              "4     0.300155 -0.052422 -0.034717  0.232278  0.058778  0.084289  0.088006   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.241675 -0.053180  0.067256  0.201138  0.034109 -0.078718 -0.066131   \n",
              "9203  0.199339 -0.105448  0.023176  0.178837  0.069476 -0.004494  0.034710   \n",
              "9204  0.223206 -0.072183 -0.013213  0.205186  0.063497  0.039164  0.070273   \n",
              "9205  0.239226 -0.064735 -0.025696  0.224218  0.070732  0.042386  0.040706   \n",
              "9206  0.274046 -0.044282  0.008441  0.249057  0.043162  0.080058  0.049930   \n",
              "\n",
              "      ...   Vetor42   Vetor43   Vetor44   Vetor45   Vetor46   Vetor47  \\\n",
              "0     ...  0.024361 -0.111328  0.157674  0.094309 -0.047458  0.157365   \n",
              "1     ...  0.008988 -0.079109  0.159296  0.085387 -0.008607  0.158519   \n",
              "2     ...  0.078032 -0.202677  0.155750  0.062291  0.007038  0.134573   \n",
              "3     ...  0.065839 -0.092451  0.308218 -0.034692 -0.032851 -0.028724   \n",
              "4     ...  0.097538 -0.161461  0.196748  0.088577 -0.080884  0.167507   \n",
              "...   ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  ... -0.082151  0.016113  0.154861  0.068700 -0.004302  0.079717   \n",
              "9203  ...  0.034035 -0.126673  0.165176  0.080313 -0.024160  0.118848   \n",
              "9204  ...  0.034706 -0.097793  0.177275  0.090335 -0.047405  0.154374   \n",
              "9205  ...  0.025414 -0.108338  0.160880  0.092846 -0.032266  0.151619   \n",
              "9206  ...  0.007607 -0.097939  0.163142  0.100946 -0.034086  0.136629   \n",
              "\n",
              "       Vetor48   Vetor49   Vetor50  sentimento  \n",
              "0    -0.033920  0.022211  0.182153           1  \n",
              "1    -0.022680  0.031107  0.189521           1  \n",
              "2     0.014635  0.034189  0.345674           2  \n",
              "3    -0.068701  0.011158  0.258413           1  \n",
              "4    -0.049984 -0.000942  0.187811           2  \n",
              "...        ...       ...       ...         ...  \n",
              "9202 -0.028388 -0.017448  0.188785           2  \n",
              "9203 -0.003502  0.087053  0.215656           2  \n",
              "9204 -0.028906  0.023713  0.179591           2  \n",
              "9205 -0.023750  0.028080  0.191956           1  \n",
              "9206 -0.024904  0.030681  0.170319           0  \n",
              "\n",
              "[9207 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3ffb33c-8c1d-483f-9ac8-c1034a31b5b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frase</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>Vetor8</th>\n",
              "      <th>Vetor9</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor42</th>\n",
              "      <th>Vetor43</th>\n",
              "      <th>Vetor44</th>\n",
              "      <th>Vetor45</th>\n",
              "      <th>Vetor46</th>\n",
              "      <th>Vetor47</th>\n",
              "      <th>Vetor48</th>\n",
              "      <th>Vetor49</th>\n",
              "      <th>Vetor50</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>0.213634</td>\n",
              "      <td>-0.129877</td>\n",
              "      <td>0.241601</td>\n",
              "      <td>-0.075002</td>\n",
              "      <td>-0.015629</td>\n",
              "      <td>0.206194</td>\n",
              "      <td>0.072658</td>\n",
              "      <td>0.055472</td>\n",
              "      <td>0.061554</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024361</td>\n",
              "      <td>-0.111328</td>\n",
              "      <td>0.157674</td>\n",
              "      <td>0.094309</td>\n",
              "      <td>-0.047458</td>\n",
              "      <td>0.157365</td>\n",
              "      <td>-0.033920</td>\n",
              "      <td>0.022211</td>\n",
              "      <td>0.182153</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>0.222697</td>\n",
              "      <td>-0.124886</td>\n",
              "      <td>0.213157</td>\n",
              "      <td>-0.059091</td>\n",
              "      <td>-0.010530</td>\n",
              "      <td>0.201566</td>\n",
              "      <td>0.071898</td>\n",
              "      <td>0.033920</td>\n",
              "      <td>0.059524</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>-0.079109</td>\n",
              "      <td>0.159296</td>\n",
              "      <td>0.085387</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>0.158519</td>\n",
              "      <td>-0.022680</td>\n",
              "      <td>0.031107</td>\n",
              "      <td>0.189521</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>0.265227</td>\n",
              "      <td>-0.068285</td>\n",
              "      <td>0.152235</td>\n",
              "      <td>-0.044329</td>\n",
              "      <td>-0.102729</td>\n",
              "      <td>0.141353</td>\n",
              "      <td>0.092800</td>\n",
              "      <td>0.113174</td>\n",
              "      <td>0.015783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078032</td>\n",
              "      <td>-0.202677</td>\n",
              "      <td>0.155750</td>\n",
              "      <td>0.062291</td>\n",
              "      <td>0.007038</td>\n",
              "      <td>0.134573</td>\n",
              "      <td>0.014635</td>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.345674</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sim]</td>\n",
              "      <td>0.166258</td>\n",
              "      <td>-0.029796</td>\n",
              "      <td>0.204045</td>\n",
              "      <td>-0.297490</td>\n",
              "      <td>0.046077</td>\n",
              "      <td>0.140763</td>\n",
              "      <td>0.035251</td>\n",
              "      <td>-0.174491</td>\n",
              "      <td>0.211817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065839</td>\n",
              "      <td>-0.092451</td>\n",
              "      <td>0.308218</td>\n",
              "      <td>-0.034692</td>\n",
              "      <td>-0.032851</td>\n",
              "      <td>-0.028724</td>\n",
              "      <td>-0.068701</td>\n",
              "      <td>0.011158</td>\n",
              "      <td>0.258413</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>0.187512</td>\n",
              "      <td>-0.183612</td>\n",
              "      <td>0.300155</td>\n",
              "      <td>-0.052422</td>\n",
              "      <td>-0.034717</td>\n",
              "      <td>0.232278</td>\n",
              "      <td>0.058778</td>\n",
              "      <td>0.084289</td>\n",
              "      <td>0.088006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097538</td>\n",
              "      <td>-0.161461</td>\n",
              "      <td>0.196748</td>\n",
              "      <td>0.088577</td>\n",
              "      <td>-0.080884</td>\n",
              "      <td>0.167507</td>\n",
              "      <td>-0.049984</td>\n",
              "      <td>-0.000942</td>\n",
              "      <td>0.187811</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>0.190917</td>\n",
              "      <td>-0.133475</td>\n",
              "      <td>0.241675</td>\n",
              "      <td>-0.053180</td>\n",
              "      <td>0.067256</td>\n",
              "      <td>0.201138</td>\n",
              "      <td>0.034109</td>\n",
              "      <td>-0.078718</td>\n",
              "      <td>-0.066131</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.082151</td>\n",
              "      <td>0.016113</td>\n",
              "      <td>0.154861</td>\n",
              "      <td>0.068700</td>\n",
              "      <td>-0.004302</td>\n",
              "      <td>0.079717</td>\n",
              "      <td>-0.028388</td>\n",
              "      <td>-0.017448</td>\n",
              "      <td>0.188785</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>0.188641</td>\n",
              "      <td>-0.119377</td>\n",
              "      <td>0.199339</td>\n",
              "      <td>-0.105448</td>\n",
              "      <td>0.023176</td>\n",
              "      <td>0.178837</td>\n",
              "      <td>0.069476</td>\n",
              "      <td>-0.004494</td>\n",
              "      <td>0.034710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034035</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>0.165176</td>\n",
              "      <td>0.080313</td>\n",
              "      <td>-0.024160</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>-0.003502</td>\n",
              "      <td>0.087053</td>\n",
              "      <td>0.215656</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>0.215474</td>\n",
              "      <td>-0.137852</td>\n",
              "      <td>0.223206</td>\n",
              "      <td>-0.072183</td>\n",
              "      <td>-0.013213</td>\n",
              "      <td>0.205186</td>\n",
              "      <td>0.063497</td>\n",
              "      <td>0.039164</td>\n",
              "      <td>0.070273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034706</td>\n",
              "      <td>-0.097793</td>\n",
              "      <td>0.177275</td>\n",
              "      <td>0.090335</td>\n",
              "      <td>-0.047405</td>\n",
              "      <td>0.154374</td>\n",
              "      <td>-0.028906</td>\n",
              "      <td>0.023713</td>\n",
              "      <td>0.179591</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>0.219393</td>\n",
              "      <td>-0.129317</td>\n",
              "      <td>0.239226</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>-0.025696</td>\n",
              "      <td>0.224218</td>\n",
              "      <td>0.070732</td>\n",
              "      <td>0.042386</td>\n",
              "      <td>0.040706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025414</td>\n",
              "      <td>-0.108338</td>\n",
              "      <td>0.160880</td>\n",
              "      <td>0.092846</td>\n",
              "      <td>-0.032266</td>\n",
              "      <td>0.151619</td>\n",
              "      <td>-0.023750</td>\n",
              "      <td>0.028080</td>\n",
              "      <td>0.191956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0.225402</td>\n",
              "      <td>-0.137580</td>\n",
              "      <td>0.274046</td>\n",
              "      <td>-0.044282</td>\n",
              "      <td>0.008441</td>\n",
              "      <td>0.249057</td>\n",
              "      <td>0.043162</td>\n",
              "      <td>0.080058</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007607</td>\n",
              "      <td>-0.097939</td>\n",
              "      <td>0.163142</td>\n",
              "      <td>0.100946</td>\n",
              "      <td>-0.034086</td>\n",
              "      <td>0.136629</td>\n",
              "      <td>-0.024904</td>\n",
              "      <td>0.030681</td>\n",
              "      <td>0.170319</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3ffb33c-8c1d-483f-9ac8-c1034a31b5b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3ffb33c-8c1d-483f-9ac8-c1034a31b5b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3ffb33c-8c1d-483f-9ac8-c1034a31b5b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação treino e teste"
      ],
      "metadata": {
        "id": "oALFWhzENEtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = df_vec[\"Frase\"], df_vec[\"sentimento\"]\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "words = [\"o\", \"ao\", 'aos', 'os', 'a', 'as', 'e', 'um', 'uma', \n",
        "        'ele', 'ela', 'eles', 'elas', 'do', 'da', 'dos', 'das', \n",
        "        'de', 'no', 'na', 'nos', 'nas', 'pelo', 'pela', 'pelos', \n",
        "        'pelas', 'num', 'numa', 'nuns', 'numas', 'dum', 'duma', \n",
        "        'duns', 'dumas']\n",
        "\n",
        "x_filter = []\n",
        "\n",
        "for title in x:\n",
        "  for word in words:\n",
        "    title = title.replace(word, '')\n",
        "  x_filter.append(title)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_filter)\n",
        "\n",
        "vocab = len(tokenizer.word_docs) + 1\n",
        "\n",
        "x_filter = tokenizer.texts_to_sequences(x_filter)\n",
        "\n",
        "max_length = max([len(z) for z in x_filter])\n",
        "x_filter = pad_sequences(x_filter, maxlen=max_length, padding='post')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_filter, y, test_size=0.33)\n",
        "\n",
        "print(\"Tamanho de x:\", len(x_filter))\n",
        "print(\"Tamanho de y:\", len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN3S4IYziYGZ",
        "outputId": "7a8e13d6-9b91-4d18-8772-d3521c894dc4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de x: 9207\n",
            "Tamanho de y: 9207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criação do modelo"
      ],
      "metadata": {
        "id": "UlXu-OuxNIUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "model_df_vec = Sequential()\n",
        "model_df_vec.add(Embedding(input_dim=vocab, output_dim=80, input_length=max_length, trainable=True))\n",
        "model_df_vec.add(GlobalMaxPooling1D())\n",
        "model_df_vec.add(Dropout(0.3))\n",
        "model_df_vec.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model_df_vec.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[recall])\n",
        "\n",
        "mc = ModelCheckpoint('weight.best.hdf5', monitor='val_acc', save_best_only=True, mode='max')\n",
        "\n",
        "model_df_vec.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=10, callbacks=[mc])\n",
        "\n",
        "print(model_df_vec.evaluate(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvnPmUbskMSn",
        "outputId": "28934d3d-2252-4960-96c6-064a6fdfdee4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "191/193 [============================>.] - ETA: 0s - loss: 1.0039 - recall: 1.1904"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 21ms/step - loss: 1.0025 - recall: 1.1884 - val_loss: 0.9031 - val_recall: 1.2317\n",
            "Epoch 2/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.8272 - recall: 1.2215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 22ms/step - loss: 0.8272 - recall: 1.2215 - val_loss: 0.7758 - val_recall: 1.2099\n",
            "Epoch 3/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.6989 - recall: 1.2187"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 27ms/step - loss: 0.6989 - recall: 1.2187 - val_loss: 0.7066 - val_recall: 1.2012\n",
            "Epoch 4/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.6036 - recall: 1.1947"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 21ms/step - loss: 0.6036 - recall: 1.1940 - val_loss: 0.6648 - val_recall: 1.1512\n",
            "Epoch 5/10\n",
            "191/193 [============================>.] - ETA: 0s - loss: 0.5130 - recall: 1.1655"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 21ms/step - loss: 0.5130 - recall: 1.1656 - val_loss: 0.6397 - val_recall: 1.1308\n",
            "Epoch 6/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.4486 - recall: 1.1320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 26ms/step - loss: 0.4499 - recall: 1.1323 - val_loss: 0.6260 - val_recall: 1.1403\n",
            "Epoch 7/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.3972 - recall: 1.1198"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 7s 36ms/step - loss: 0.3964 - recall: 1.1194 - val_loss: 0.6194 - val_recall: 1.1348\n",
            "Epoch 8/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.3443 - recall: 1.1008"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 6s 30ms/step - loss: 0.3443 - recall: 1.1008 - val_loss: 0.6188 - val_recall: 1.1231\n",
            "Epoch 9/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.3041 - recall: 1.0893"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 27ms/step - loss: 0.3041 - recall: 1.0893 - val_loss: 0.6209 - val_recall: 1.1243\n",
            "Epoch 10/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.2760 - recall: 1.0743"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193/193 [==============================] - 4s 21ms/step - loss: 0.2760 - recall: 1.0743 - val_loss: 0.6274 - val_recall: 1.1126\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 0.6274 - recall: 1.1126\n",
            "[0.6273788213729858, 1.1126384735107422]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relatório de Classificação e matiz de confusão"
      ],
      "metadata": {
        "id": "jRXaQr0dd0jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model_df_vec.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1) \n",
        "\n",
        "classification = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSezoCn1jFxX",
        "outputId": "c3962fb2-1fcb-4b01-f52c-5b661534014b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95/95 [==============================] - 0s 2ms/step\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70       633\n",
            "           1       0.79      0.74      0.77      1308\n",
            "           2       0.71      0.77      0.74      1098\n",
            "\n",
            "    accuracy                           0.74      3039\n",
            "   macro avg       0.73      0.74      0.73      3039\n",
            "weighted avg       0.74      0.74      0.74      3039\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "classes = ['Classe 1', 'Classe 2', 'Classe 3']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot\n",
        "=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "PNwLCtugd5Pn",
        "outputId": "042ac7f4-a10e-481f-b771-e4605145616c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportação com a biblioteca pickle"
      ],
      "metadata": {
        "id": "rHt4zf7INK_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('redeNeural_word2vec_cbow_sprint3.pkl', 'wb') as arquivo:\n",
        "    pickle.dump(model_df_vec, arquivo)\n",
        "with open('redeNeural_word2vec_cbow_sprint3.pkl', 'rb') as arquivo:\n",
        "    redeNeural_word2vec_cbow_sprint3 = pickle.load(arquivo)"
      ],
      "metadata": {
        "id": "PgG5RYKK_ylr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção da rede neural + resultados - word2vec com embedding layer"
      ],
      "metadata": {
        "id": "d1JXO4zpkpLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A rede neural abaixo foi desenvolvida com o tutorial mencionado no ínicio do notebook, que, nesse caso o dataframe utilizado é a variável do Word2Vec com Embedding Layer."
      ],
      "metadata": {
        "id": "2C1W-HD6Pt86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe do word2vec com embedding layer"
      ],
      "metadata": {
        "id": "vYpXV3hPNPn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_word2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "0pkNRpt0kbZZ",
        "outputId": "d993068d-7d96-49a5-a49b-f4d531169139"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          texto_tratado  sentimentoNumerico  \\\n",
              "0     [alvarez, marsal, estar, conosco, sportainmet,...                   1   \n",
              "1     [btgpactual, with, makerepost, entender, impac...                   1   \n",
              "2                                 [minuto, touro, ouro]                   2   \n",
              "3                                                 [sim]                   1   \n",
              "4         [querer, saber, banking, próprio, administro]                   2   \n",
              "...                                                 ...                 ...   \n",
              "9202                            [excelente, explicação]                   2   \n",
              "9203                    [atendar, telefone, amor, deus]                   2   \n",
              "9204  [saber, qual, grande, fiis, mercado, selecione...                   2   \n",
              "9205  [erro, financeiro, eliminar, antes, ano, _, pa...                   1   \n",
              "9206  [porque, morning, call, aparecer, spotify, atu...                   0   \n",
              "\n",
              "        Vetor0    Vetor1    Vetor2    Vetor3    Vetor4    Vetor5    Vetor6  \\\n",
              "0     0.108135 -0.027515 -0.578618 -0.311223  0.342741  0.582513 -0.156178   \n",
              "1     0.111517  0.001278 -0.552969 -0.288248  0.303032  0.582805 -0.152977   \n",
              "2    -0.055194  0.083907 -0.614759 -0.327277  0.337467  0.614014 -0.234232   \n",
              "3     0.346554  0.100439 -0.466173  0.043146  0.428946  0.523282 -0.110418   \n",
              "4     0.046847 -0.010748 -0.590074 -0.260886  0.367818  0.548250 -0.176722   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9202  0.206777 -0.020575 -0.546014 -0.393732  0.176287  0.581065 -0.148453   \n",
              "9203  0.144401  0.017314 -0.603351 -0.358521  0.407179  0.616990 -0.215791   \n",
              "9204  0.089300 -0.053939 -0.570320 -0.366888  0.324487  0.588473 -0.136371   \n",
              "9205  0.098567 -0.042418 -0.610832 -0.344497  0.347288  0.611232 -0.160629   \n",
              "9206  0.077178  0.004275 -0.589861 -0.357459  0.381499  0.599922 -0.210750   \n",
              "\n",
              "        Vetor7  ...   Vetor90   Vetor91   Vetor92   Vetor93   Vetor94  \\\n",
              "0    -0.078588  ... -0.331011  0.171356  0.115854  0.407576 -0.028241   \n",
              "1    -0.093876  ... -0.310332  0.174199  0.099849  0.379870 -0.034922   \n",
              "2    -0.012530  ... -0.366691  0.330312  0.197640  0.398107  0.051024   \n",
              "3     0.002156  ... -0.289289  0.026381  0.406109  0.390878  0.061961   \n",
              "4    -0.048525  ... -0.355716  0.161371  0.110116  0.369940 -0.011467   \n",
              "...        ...  ...       ...       ...       ...       ...       ...   \n",
              "9202 -0.049564  ... -0.263816  0.147015  0.051944  0.460383 -0.122683   \n",
              "9203 -0.035666  ... -0.403889  0.213475  0.126607  0.399203 -0.023190   \n",
              "9204 -0.078024  ... -0.287883  0.167735  0.107425  0.404131 -0.069292   \n",
              "9205 -0.092984  ... -0.323466  0.199106  0.087568  0.430179 -0.046208   \n",
              "9206 -0.062320  ... -0.396163  0.180069  0.116189  0.392327 -0.041298   \n",
              "\n",
              "       Vetor95   Vetor96   Vetor97   Vetor98   Vetor99  \n",
              "0    -0.249628 -0.069736  0.052952  0.322158 -0.108738  \n",
              "1    -0.238013 -0.091016  0.070340  0.321247 -0.079625  \n",
              "2    -0.268653  0.009458  0.124287  0.401329 -0.075046  \n",
              "3    -0.334896 -0.101127  0.189571  0.335559 -0.141967  \n",
              "4    -0.228353 -0.078955  0.014221  0.312695 -0.017164  \n",
              "...        ...       ...       ...       ...       ...  \n",
              "9202 -0.294831 -0.124148 -0.062046  0.367368 -0.002227  \n",
              "9203 -0.247552 -0.013290  0.064286  0.328812 -0.115048  \n",
              "9204 -0.231209 -0.054285  0.022797  0.360763 -0.075168  \n",
              "9205 -0.250215 -0.102156  0.031142  0.348474 -0.088865  \n",
              "9206 -0.225956 -0.010667  0.058244  0.296054 -0.078506  \n",
              "\n",
              "[9207 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7912705a-e13d-4b78-9849-72ee0b007cb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_tratado</th>\n",
              "      <th>sentimentoNumerico</th>\n",
              "      <th>Vetor0</th>\n",
              "      <th>Vetor1</th>\n",
              "      <th>Vetor2</th>\n",
              "      <th>Vetor3</th>\n",
              "      <th>Vetor4</th>\n",
              "      <th>Vetor5</th>\n",
              "      <th>Vetor6</th>\n",
              "      <th>Vetor7</th>\n",
              "      <th>...</th>\n",
              "      <th>Vetor90</th>\n",
              "      <th>Vetor91</th>\n",
              "      <th>Vetor92</th>\n",
              "      <th>Vetor93</th>\n",
              "      <th>Vetor94</th>\n",
              "      <th>Vetor95</th>\n",
              "      <th>Vetor96</th>\n",
              "      <th>Vetor97</th>\n",
              "      <th>Vetor98</th>\n",
              "      <th>Vetor99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[alvarez, marsal, estar, conosco, sportainmet,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108135</td>\n",
              "      <td>-0.027515</td>\n",
              "      <td>-0.578618</td>\n",
              "      <td>-0.311223</td>\n",
              "      <td>0.342741</td>\n",
              "      <td>0.582513</td>\n",
              "      <td>-0.156178</td>\n",
              "      <td>-0.078588</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.331011</td>\n",
              "      <td>0.171356</td>\n",
              "      <td>0.115854</td>\n",
              "      <td>0.407576</td>\n",
              "      <td>-0.028241</td>\n",
              "      <td>-0.249628</td>\n",
              "      <td>-0.069736</td>\n",
              "      <td>0.052952</td>\n",
              "      <td>0.322158</td>\n",
              "      <td>-0.108738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[btgpactual, with, makerepost, entender, impac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111517</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>-0.552969</td>\n",
              "      <td>-0.288248</td>\n",
              "      <td>0.303032</td>\n",
              "      <td>0.582805</td>\n",
              "      <td>-0.152977</td>\n",
              "      <td>-0.093876</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310332</td>\n",
              "      <td>0.174199</td>\n",
              "      <td>0.099849</td>\n",
              "      <td>0.379870</td>\n",
              "      <td>-0.034922</td>\n",
              "      <td>-0.238013</td>\n",
              "      <td>-0.091016</td>\n",
              "      <td>0.070340</td>\n",
              "      <td>0.321247</td>\n",
              "      <td>-0.079625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[minuto, touro, ouro]</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.055194</td>\n",
              "      <td>0.083907</td>\n",
              "      <td>-0.614759</td>\n",
              "      <td>-0.327277</td>\n",
              "      <td>0.337467</td>\n",
              "      <td>0.614014</td>\n",
              "      <td>-0.234232</td>\n",
              "      <td>-0.012530</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.366691</td>\n",
              "      <td>0.330312</td>\n",
              "      <td>0.197640</td>\n",
              "      <td>0.398107</td>\n",
              "      <td>0.051024</td>\n",
              "      <td>-0.268653</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.124287</td>\n",
              "      <td>0.401329</td>\n",
              "      <td>-0.075046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[sim]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.346554</td>\n",
              "      <td>0.100439</td>\n",
              "      <td>-0.466173</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>0.428946</td>\n",
              "      <td>0.523282</td>\n",
              "      <td>-0.110418</td>\n",
              "      <td>0.002156</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.289289</td>\n",
              "      <td>0.026381</td>\n",
              "      <td>0.406109</td>\n",
              "      <td>0.390878</td>\n",
              "      <td>0.061961</td>\n",
              "      <td>-0.334896</td>\n",
              "      <td>-0.101127</td>\n",
              "      <td>0.189571</td>\n",
              "      <td>0.335559</td>\n",
              "      <td>-0.141967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[querer, saber, banking, próprio, administro]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.046847</td>\n",
              "      <td>-0.010748</td>\n",
              "      <td>-0.590074</td>\n",
              "      <td>-0.260886</td>\n",
              "      <td>0.367818</td>\n",
              "      <td>0.548250</td>\n",
              "      <td>-0.176722</td>\n",
              "      <td>-0.048525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355716</td>\n",
              "      <td>0.161371</td>\n",
              "      <td>0.110116</td>\n",
              "      <td>0.369940</td>\n",
              "      <td>-0.011467</td>\n",
              "      <td>-0.228353</td>\n",
              "      <td>-0.078955</td>\n",
              "      <td>0.014221</td>\n",
              "      <td>0.312695</td>\n",
              "      <td>-0.017164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>[excelente, explicação]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.206777</td>\n",
              "      <td>-0.020575</td>\n",
              "      <td>-0.546014</td>\n",
              "      <td>-0.393732</td>\n",
              "      <td>0.176287</td>\n",
              "      <td>0.581065</td>\n",
              "      <td>-0.148453</td>\n",
              "      <td>-0.049564</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263816</td>\n",
              "      <td>0.147015</td>\n",
              "      <td>0.051944</td>\n",
              "      <td>0.460383</td>\n",
              "      <td>-0.122683</td>\n",
              "      <td>-0.294831</td>\n",
              "      <td>-0.124148</td>\n",
              "      <td>-0.062046</td>\n",
              "      <td>0.367368</td>\n",
              "      <td>-0.002227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9203</th>\n",
              "      <td>[atendar, telefone, amor, deus]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.144401</td>\n",
              "      <td>0.017314</td>\n",
              "      <td>-0.603351</td>\n",
              "      <td>-0.358521</td>\n",
              "      <td>0.407179</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>-0.215791</td>\n",
              "      <td>-0.035666</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403889</td>\n",
              "      <td>0.213475</td>\n",
              "      <td>0.126607</td>\n",
              "      <td>0.399203</td>\n",
              "      <td>-0.023190</td>\n",
              "      <td>-0.247552</td>\n",
              "      <td>-0.013290</td>\n",
              "      <td>0.064286</td>\n",
              "      <td>0.328812</td>\n",
              "      <td>-0.115048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>[saber, qual, grande, fiis, mercado, selecione...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.089300</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>-0.570320</td>\n",
              "      <td>-0.366888</td>\n",
              "      <td>0.324487</td>\n",
              "      <td>0.588473</td>\n",
              "      <td>-0.136371</td>\n",
              "      <td>-0.078024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.287883</td>\n",
              "      <td>0.167735</td>\n",
              "      <td>0.107425</td>\n",
              "      <td>0.404131</td>\n",
              "      <td>-0.069292</td>\n",
              "      <td>-0.231209</td>\n",
              "      <td>-0.054285</td>\n",
              "      <td>0.022797</td>\n",
              "      <td>0.360763</td>\n",
              "      <td>-0.075168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9205</th>\n",
              "      <td>[erro, financeiro, eliminar, antes, ano, _, pa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.098567</td>\n",
              "      <td>-0.042418</td>\n",
              "      <td>-0.610832</td>\n",
              "      <td>-0.344497</td>\n",
              "      <td>0.347288</td>\n",
              "      <td>0.611232</td>\n",
              "      <td>-0.160629</td>\n",
              "      <td>-0.092984</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323466</td>\n",
              "      <td>0.199106</td>\n",
              "      <td>0.087568</td>\n",
              "      <td>0.430179</td>\n",
              "      <td>-0.046208</td>\n",
              "      <td>-0.250215</td>\n",
              "      <td>-0.102156</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.348474</td>\n",
              "      <td>-0.088865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>[porque, morning, call, aparecer, spotify, atu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.077178</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>-0.589861</td>\n",
              "      <td>-0.357459</td>\n",
              "      <td>0.381499</td>\n",
              "      <td>0.599922</td>\n",
              "      <td>-0.210750</td>\n",
              "      <td>-0.062320</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.396163</td>\n",
              "      <td>0.180069</td>\n",
              "      <td>0.116189</td>\n",
              "      <td>0.392327</td>\n",
              "      <td>-0.041298</td>\n",
              "      <td>-0.225956</td>\n",
              "      <td>-0.010667</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.296054</td>\n",
              "      <td>-0.078506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9207 rows × 102 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7912705a-e13d-4b78-9849-72ee0b007cb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7912705a-e13d-4b78-9849-72ee0b007cb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7912705a-e13d-4b78-9849-72ee0b007cb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação treino e teste\n"
      ],
      "metadata": {
        "id": "OxMPcc--NU5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = df_word2vec[\"texto_tratado\"], df_word2vec[\"sentimentoNumerico\"]\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "words = [\"o\", \"ao\", 'aos', 'os', 'a', 'as', 'e', 'um', 'uma', \n",
        "        'ele', 'ela', 'eles', 'elas', 'do', 'da', 'dos', 'das', \n",
        "        'de', 'no', 'na', 'nos', 'nas', 'pelo', 'pela', 'pelos', \n",
        "        'pelas', 'num', 'numa', 'nuns', 'numas', 'dum', 'duma', \n",
        "        'duns', 'dumas']\n",
        "\n",
        "x_filter = []\n",
        "\n",
        "for title in x:\n",
        "  for word in words:\n",
        "    title = title.replace(word, '')\n",
        "  x_filter.append(title)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_filter)\n",
        "\n",
        "vocab = len(tokenizer.word_docs) + 1\n",
        "\n",
        "x_filter = tokenizer.texts_to_sequences(x_filter)\n",
        "\n",
        "max_length = max([len(z) for z in x_filter])\n",
        "x_filter = pad_sequences(x_filter, maxlen=max_length, padding='post')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_filter, y, test_size=0.33)\n",
        "\n",
        "print(\"Tamanho de x:\", len(x_filter))\n",
        "print(\"Tamanho de y:\", len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruSTwPA2k5AN",
        "outputId": "d810da0b-6631-4c51-b483-d211d70dc61b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de x: 9207\n",
            "Tamanho de y: 9207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criação do modelo"
      ],
      "metadata": {
        "id": "-KnLk7aSNXxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "model_df_word2vec = Sequential()\n",
        "model_df_word2vec.add(Embedding(input_dim=vocab, output_dim=80, input_length=max_length, trainable=True))\n",
        "model_df_word2vec.add(GlobalMaxPooling1D())\n",
        "model_df_word2vec.add(Dropout(0.3))\n",
        "model_df_word2vec.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model_df_word2vec.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[recall])\n",
        "\n",
        "mc = ModelCheckpoint('weight.best.hdf5', monitor='val_acc', save_best_only=True, mode='max')\n",
        "\n",
        "model_df_word2vec.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=10, callbacks=[mc])\n",
        "\n",
        "print(model_df_word2vec.evaluate(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l985gRzXk_zk",
        "outputId": "1e76d2b0-f5ce-4f22-98d1-f7752d930da7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 1.0041 - recall: 1.1734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 6s 27ms/step - loss: 1.0041 - recall: 1.1734 - val_loss: 0.9027 - val_recall: 1.2180\n",
            "Epoch 2/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.8267 - recall: 1.1979"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 25ms/step - loss: 0.8270 - recall: 1.1991 - val_loss: 0.7699 - val_recall: 1.2051\n",
            "Epoch 3/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.6951 - recall: 1.2010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 22ms/step - loss: 0.6948 - recall: 1.2015 - val_loss: 0.7041 - val_recall: 1.1957\n",
            "Epoch 4/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.5995 - recall: 1.1972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 23ms/step - loss: 0.5997 - recall: 1.1962 - val_loss: 0.6654 - val_recall: 1.1787\n",
            "Epoch 5/10\n",
            "191/193 [============================>.] - ETA: 0s - loss: 0.5138 - recall: 1.1630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 28ms/step - loss: 0.5142 - recall: 1.1632 - val_loss: 0.6418 - val_recall: 1.1660\n",
            "Epoch 6/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.4435 - recall: 1.1323"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 22ms/step - loss: 0.4435 - recall: 1.1323 - val_loss: 0.6298 - val_recall: 1.1490\n",
            "Epoch 7/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 0.3859 - recall: 1.1150"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 4s 21ms/step - loss: 0.3859 - recall: 1.1150 - val_loss: 0.6220 - val_recall: 1.1206\n",
            "Epoch 8/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.3431 - recall: 1.0897"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 6s 31ms/step - loss: 0.3430 - recall: 1.0902 - val_loss: 0.6213 - val_recall: 1.1173\n",
            "Epoch 9/10\n",
            "190/193 [============================>.] - ETA: 0s - loss: 0.3000 - recall: 1.0785"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r193/193 [==============================] - 5s 25ms/step - loss: 0.3009 - recall: 1.0783 - val_loss: 0.6238 - val_recall: 1.1129\n",
            "Epoch 10/10\n",
            "192/193 [============================>.] - ETA: 0s - loss: 0.2681 - recall: 1.0712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193/193 [==============================] - 4s 21ms/step - loss: 0.2677 - recall: 1.0708 - val_loss: 0.6277 - val_recall: 1.1118\n",
            "95/95 [==============================] - 0s 2ms/step - loss: 0.6277 - recall: 1.1118\n",
            "[0.6277082562446594, 1.111788272857666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relatório de Classificação e matiz de confusão"
      ],
      "metadata": {
        "id": "u1Tg4iPWd1MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model_df_word2vec.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1) \n",
        "\n",
        "classification = classification_report(y_test, y_pred_classes)\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcg-ECXXjHNU",
        "outputId": "54f05c29-801a-4594-b736-54507f91f736"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95/95 [==============================] - 0s 2ms/step\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.69      0.68       632\n",
            "           1       0.76      0.75      0.76      1321\n",
            "           2       0.72      0.72      0.72      1086\n",
            "\n",
            "    accuracy                           0.73      3039\n",
            "   macro avg       0.72      0.72      0.72      3039\n",
            "weighted avg       0.73      0.73      0.73      3039\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "classes = ['Classe 1', 'Classe 2', 'Classe 3']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot\n",
        "=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "BYc3ZY5hd6Qm",
        "outputId": "1a7dc900-9cc2-444f-cd51-2bda5a61791d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportação com a biblioteca pickle "
      ],
      "metadata": {
        "id": "rZataI5cNbSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('redeNeural_word2vec_embedding_sprint3.pkl', 'wb') as arquivo:\n",
        "    pickle.dump(model_df_word2vec, arquivo)\n",
        "with open('redeNeural_word2vec_embedding_sprint3.pkl', 'rb') as arquivo:\n",
        "    redeNeural_word2vec_embedding_sprint3 = pickle.load(arquivo)"
      ],
      "metadata": {
        "id": "rXw6Wv49lJgj"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}